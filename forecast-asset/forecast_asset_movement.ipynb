{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cf04c4-e1ce-4eb2-b82c-8b98bae04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def forecast_asset_movement(request):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55257eb9-7ddb-4aa6-8d11-bc42344a6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List parameter as belows\n",
      "today=2023-05-26\n",
      "model_id=spy-ema1\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/61573102/calling-a-google-cloud-function-from-within-python\n",
    "#https://medium.com/google-cloud/setup-and-invoke-cloud-functions-using-python-e801a8633096\n",
    "#https://medium.com/google-cloud/gcp-cloud-functions-develop-it-the-right-way-82e633b07756\n",
    "\n",
    "model_id='spy-ema1'\n",
    "today='2023-05-26'\n",
    "\n",
    "# if request.get_json():\n",
    "#     print(\"JSON Post Date Info\") # Post Method\n",
    "#     request_json = request.get_json()\n",
    "#     today=request_json['TODAY']\n",
    "#     model_id=request_json['MODEL_ID']\n",
    "# else:\n",
    "#     print(\"Enviroment Variable Info\")\n",
    "#     today=os.environ.get('TODAY', '') \n",
    "#     #today=os.environ.get('TODAY', '2023-04-28')  \n",
    "#     model_id=os.environ.get('MODEL_ID', 'spy-ema1')  \n",
    "print(\"List parameter as belows\")\n",
    "print(f\"today={today}\")\n",
    "print(f\"model_id={model_id}\")\n",
    "\n",
    "\n",
    "loadModelMode='local'   # local,gcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e81398-c118-43c5-8a1e-68cfbd0d5ea2",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54cabd15-5e81-4075-a4a7-9aba2ebff632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.FinAssetForecast.fin_movement_forecast\n",
      "pongthorn.FinAssetForecast.fin_data\n",
      "pongthorn.FinAssetForecast.model_ts_metadata\n"
     ]
    }
   ],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='FinAssetForecast'\n",
    "table_id = f\"{projectId}.{dataset_id}.fin_movement_forecast\"\n",
    "table_data_id = f\"{projectId}.{dataset_id}.fin_data\"\n",
    "table_model_id= f\"{projectId}.{dataset_id}.model_ts_metadata\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "print(table_model_id)\n",
    "\n",
    "# json_credential_file=r'C:\\Windows\\pongthorn-5decdc5124f5.json'\n",
    "# credentials = service_account.Credentials.from_service_account_file(json_credential_file)\n",
    "# client = bigquery.Client(project=projectId,credentials=credentials )\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a7f48-7759-48bf-8806-089595651be4",
   "metadata": {},
   "source": [
    "# Load Model MetaData Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7549f76c-4efe-49a5-b201-ba34b58e7172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT * FROM `pongthorn.FinAssetForecast.model_ts_metadata`  where model_id='spy-ema1'\n",
      "\n",
      "model_id                                                     spy-ema1\n",
      "asset                                                             SPY\n",
      "prediction                                                       EMA1\n",
      "gs_model_path              gs://demo-ts-forecast-pongthorn/model-ema1\n",
      "model_file                   EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\n",
      "scaler_file              scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "scaler_pred_file    scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sqlModelMt=f\"\"\"\n",
    "SELECT * FROM `{table_model_id}`  where model_id='{model_id}'\n",
    "\"\"\"\n",
    "print(sqlModelMt)\n",
    "dfModelMeta=load_data_bq(sqlModelMt)\n",
    "if dfModelMeta.empty==False:\n",
    "    modelMeta=dfModelMeta.iloc[0,:]\n",
    "    asset_name=modelMeta['asset']\n",
    "    prediction_name=modelMeta['prediction']\n",
    "    model_path=modelMeta['gs_model_path']\n",
    "    model_file=modelMeta['model_file']\n",
    "    scaler_file=modelMeta['scaler_file']\n",
    "    scalerPred_file=modelMeta['scaler_pred_file']\n",
    "    print(modelMeta)\n",
    "    \n",
    "else: \n",
    "    raise Exception(f\"Not found model id  {model_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"{today} - {asset_name} -{prediction_name}\")\n",
    "# print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from local\n",
      "model/model-ema1/EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\n",
      "model/model-ema1/scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "model/model-ema1/scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n"
     ]
    }
   ],
   "source": [
    "if loadModelMode=='local':\n",
    " objectPaht=\"model/model-ema1\"\n",
    "else:\n",
    " objectPaht=model_path  \n",
    "\n",
    "model_path=f\"{objectPaht}/{model_file}\"\n",
    "scale_input_path=f\"{objectPaht}/{scaler_file}\"\n",
    "scale_output_path=f\"{objectPaht}/{scalerPred_file}\"\n",
    "\n",
    "print(f\"load model from {loadModelMode}\")   \n",
    "print(model_path)\n",
    "print(scale_input_path)\n",
    "print(scale_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "443426bb-6329-48d8-9c1b-f5a51c31b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Scaler Object Summary\n",
      "Scaler Max-Min\n",
      "=====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if loadModelMode=='local':\n",
    "    try:\n",
    "        print(\"Model and Scaler Object Summary\")\n",
    "        x_model = load_model(model_path)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex)) \n",
    "    \n",
    "    try:\n",
    "        print(\"Scaler Max-Min\")\n",
    "        x_scaler = joblib.load(scale_input_path)\n",
    "        x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex))\n",
    "\n",
    "    print(\"=====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205bf465-9f2b-417c-86aa-22a5062f4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModelMode=='gcs':\n",
    " try:    \n",
    "    gcs_client = storage.Client()\n",
    "\n",
    "    with open(scaler_file, 'wb') as scaler_f, open(scalerPred_file, 'wb') as scaler_pred_f,open(model_file, 'wb') as model_f:\n",
    "        gcs_client.download_blob_to_file(scale_input_path, scaler_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(scale_output_path, scaler_pred_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(model_path, model_f\n",
    "        )\n",
    "\n",
    "    x_scaler = joblib.load(scaler_file)\n",
    "    x_scalerPred=joblib.load(scalerPred_file)\n",
    "    x_model = load_model(model_file)\n",
    " except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbc6a3f-8264-4b1d-9424-34a3cf16177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 180)               131040    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 180)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1810      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,850\n",
      "Trainable params: 132,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n"
     ]
    }
   ],
   "source": [
    "print(x_model.summary())\n",
    "#(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize TS Model Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-03 16:42:43\n"
     ]
    }
   ],
   "source": [
    "date_col='Date'\n",
    "prediction_col=prediction_name\n",
    "feature_cols=[prediction_name]\n",
    "\n",
    "input_sequence_length =60\n",
    "output_sequence_length =10\n",
    "\n",
    "nLastData=input_sequence_length*2\n",
    "\n",
    "# dt_imported=datetime.now()\n",
    "dt_imported=datetime.now(timezone.utc)\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b682d76-f7b1-45b2-92c1-78a5c0e7af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    select Date as LastDate  from `pongthorn.FinAssetForecast.fin_data` where Symbol='SPY' \n",
      "    and Date='2023-05-26'\n",
      "    \n",
      "     LastDate\n",
      "0  2023-05-26\n",
      "Forecast EMA1 movement of  SPY at 2023-05-26\n"
     ]
    }
   ],
   "source": [
    "lastDate=None\n",
    "if today=='':\n",
    "    sqlLastDate=f\"\"\" select max(Date) as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \"\"\"\n",
    "\n",
    "else:\n",
    "    sqlLastDate=f\"\"\" \n",
    "    select Date as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \n",
    "    and Date='{today}'\n",
    "    \"\"\"\n",
    "print(sqlLastDate)\n",
    "results = client.query(sqlLastDate)\n",
    "dfLastDate=results.to_dataframe()\n",
    "print(dfLastDate)\n",
    "if dfLastDate.empty:\n",
    "    print( f\"Not found price data at {today}  of {asset_name}\")\n",
    "    # return f\"Not found price data at {today}  of {asset_name}\"\n",
    "else:\n",
    "    lastDate=dfLastDate.iloc[0,0]\n",
    "    today=lastDate.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "print(f\"Forecast {prediction_col} movement of  {asset_name} at {today}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4835aad-60d9-4c16-b69e-7da926e9ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get last price of SPY\n",
      "select prediction_date,asset_name,prediction_name,pred_timestamp from `pongthorn.FinAssetForecast.fin_movement_forecast` \n",
      "where prediction_date='2023-05-26' and   asset_name='SPY' and prediction_name='EMA1'\n",
      "order by pred_timestamp \n",
      "\n",
      "SPY-EMA1 at 2023-05-26 has not been predicted price movement yet.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get last price of {asset_name}\")\n",
    "sqlLastPred=f\"\"\"select prediction_date,asset_name,prediction_name,pred_timestamp from `{table_id}` \n",
    "where prediction_date='{today}' and   asset_name='{asset_name}' and prediction_name='{prediction_col}'\n",
    "order by pred_timestamp \n",
    "\"\"\"\n",
    "print(sqlLastPred)\n",
    "dfLastPred=load_data_bq(sqlLastPred)\n",
    "if dfLastPred.empty==False:\n",
    "   dfLastPred=dfLastPred.drop_duplicates(subset=['prediction_date','asset_name','prediction_name'],keep='last') \n",
    "   print(f\"{asset_name}-{prediction_col}-{today} has been predicted price movement\")\n",
    "   print(dfLastPred)\n",
    "   #return \"there is one record of prediction price movement\"\n",
    "else:\n",
    "   print(f\"{asset_name}-{prediction_col} at {today} has not been predicted price movement yet.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab61afa5-0cbd-46c9-895d-20ddcd23b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2023-01-26 - 2023-05-26 as input to forecast\n"
     ]
    }
   ],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT  *  FROM `pongthorn.FinAssetForecast.fin_data`  \n",
      "Where  Date between  DATE_SUB(DATE '2023-06-01', INTERVAL 120 DAY) \n",
      "and '2023-06-01' and Symbol='SPY' order by Date,ImportDateTime\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 84 entries, 2023-02-01 to 2023-06-01\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Symbol          84 non-null     object        \n",
      " 1   Close           84 non-null     float64       \n",
      " 2   EMA1            84 non-null     float64       \n",
      " 3   EMA2            84 non-null     float64       \n",
      " 4   MACD            84 non-null     float64       \n",
      " 5   SIGNAL          84 non-null     float64       \n",
      " 6   ImportDateTime  84 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "           Symbol   Close             ImportDateTime\n",
      "Date                                                \n",
      "2023-02-01    SPY  410.80 2023-06-01 06:44:32.649830\n",
      "2023-02-02    SPY  416.78 2023-06-01 06:44:32.649830\n",
      "2023-02-03    SPY  412.35 2023-06-01 06:44:32.649830\n",
      "2023-02-06    SPY  409.83 2023-06-01 06:44:32.649830\n",
      "2023-02-07    SPY  415.19 2023-06-01 06:44:32.649830\n",
      "           Symbol       Close             ImportDateTime\n",
      "Date                                                    \n",
      "2023-05-25    SPY  414.650000 2023-06-01 06:44:32.649830\n",
      "2023-05-26    SPY  420.020000 2023-06-01 06:44:32.649830\n",
      "2023-05-30    SPY  420.180000 2023-06-01 06:44:32.649830\n",
      "2023-05-31    SPY  417.850006 2023-06-01 06:56:07.996695\n",
      "2023-06-01    SPY  421.820007 2023-06-02 01:15:04.116380\n"
     ]
    }
   ],
   "source": [
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB(DATE '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}' and Symbol='{asset_name}' order by {date_col},ImportDateTime\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df=df.drop_duplicates(subset=[date_col,'Symbol'],keep='last')\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].head())\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    # return \"no enough data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(2, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[['Close','EMA1','EMA2']])\n",
    "# plt.ylabel('Price & EMA')\n",
    "\n",
    "# ax2 = plt.subplot(2, 1, 2)\n",
    "# plt.plot(df[['MACD','SIGNAL']])\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('MACD & Signal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Feature to Predict : SIGNAL \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 60 entries, 2023-03-08 to 2023-06-01\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   SIGNAL  60 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 960.0 bytes\n",
      "None\n",
      "(60, 1)\n",
      "            SIGNAL\n",
      "Date              \n",
      "2023-03-08 -0.1360\n",
      "2023-03-09 -0.3457\n",
      "2023-03-10 -0.6468\n",
      "2023-03-13 -0.9973\n",
      "2023-03-14 -1.2921\n",
      "            SIGNAL\n",
      "Date              \n",
      "2023-05-25  1.3693\n",
      "2023-05-26  1.3881\n",
      "2023-05-30  1.4385\n",
      "2023-05-31  0.6864\n",
      "2023-06-01  0.8177\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(5))\n",
    "print(dfForPred.tail(5))\n",
    "\n",
    "# dfForPred.plot(figsize = (20, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction as Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n",
      "[[0.76776398]\n",
      " [0.76866221]\n",
      " [0.77107023]\n",
      " [0.73513617]\n",
      " [0.74140946]]\n",
      "(1, 60, 1)\n",
      "1/1 [==============================] - 0s 498ms/step\n",
      "(1, 10) [[0.71830523 0.6927993  0.66803455 0.64833355 0.6359732  0.6248889\n",
      "  0.6156411  0.60843474 0.6040622  0.6035649 ]]\n",
      "(10, 1) [[ 0.33412847]\n",
      " [-0.19971004]\n",
      " [-0.7180368 ]\n",
      " [-1.1303787 ]\n",
      " [-1.3890806 ]\n",
      " [-1.6210754 ]\n",
      " [-1.8146315 ]\n",
      " [-1.965461  ]\n",
      " [-2.0569782 ]\n",
      " [-2.0673864 ]]\n",
      "============================Summary============================\n",
      "(60, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "print(xScaled[-5:])\n",
    "\n",
    "# # Way1\n",
    "# xScaledToPredict = []\n",
    "# xScaledToPredict.append(xScaled)\n",
    "# print(len(xScaledToPredict))\n",
    "\n",
    "# yPredScaled=x_model.predict(np.array(xScaledToPredict))\n",
    "# print(yPredScaled.shape,yPredScaled)\n",
    "\n",
    "# yPred  = x_scalerPred.inverse_transform(yPredScaled.reshape(-1, 1))\n",
    "# print(yPred.shape,yPred)\n",
    "\n",
    "#Way2\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "# print(\"============================Input============================\")\n",
    "# print(xUnscaled)\n",
    "# print(\"============================Output============================\")\n",
    "# print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Predition Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2)\n",
      "            SIGNAL     Type\n",
      "Date                       \n",
      "2023-03-08 -0.1360  feature\n",
      "2023-03-09 -0.3457  feature\n",
      "2023-03-10 -0.6468  feature\n",
      "2023-03-13 -0.9973  feature\n",
      "2023-03-14 -1.2921  feature\n",
      "            SIGNAL     Type\n",
      "Date                       \n",
      "2023-05-25  1.3693  feature\n",
      "2023-05-26  1.3881  feature\n",
      "2023-05-30  1.4385  feature\n",
      "2023-05-31  0.6864  feature\n",
      "2023-06-01  0.8177  feature\n"
     ]
    }
   ],
   "source": [
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-06-02', '2023-06-05', '2023-06-06', '2023-06-07',\n",
      "               '2023-06-08', '2023-06-09', '2023-06-12', '2023-06-13',\n",
      "               '2023-06-14', '2023-06-15'],\n",
      "              dtype='datetime64[ns]', freq='B')\n",
      "(10, 2)\n",
      "              SIGNAL        Type\n",
      "Date                            \n",
      "2023-06-02  0.334128  prediction\n",
      "2023-06-05 -0.199710  prediction\n",
      "2023-06-06 -0.718037  prediction\n",
      "2023-06-07 -1.130379  prediction\n",
      "2023-06-08 -1.389081  prediction\n",
      "2023-06-09 -1.621075  prediction\n",
      "2023-06-12 -1.814631  prediction\n",
      "2023-06-13 -1.965461  prediction\n",
      "2023-06-14 -2.056978  prediction\n",
      "2023-06-15 -2.067386  prediction\n"
     ]
    }
   ],
   "source": [
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq='b',periods=output_sequence_length)\n",
    "print(datePred)\n",
    "\n",
    "dfPrediction=pd.DataFrame(data= yPred,columns=feature_cols,index=datePred)\n",
    "dfPrediction.index.name=date_col\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   prediction_date  1 non-null      object\n",
      " 1   asset_name       1 non-null      object\n",
      " 2   prediction_name  1 non-null      object\n",
      " 3   pred_timestamp   1 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 160.0+ bytes\n",
      "None\n",
      "  prediction_date asset_name prediction_name       pred_timestamp\n",
      "0      2023-06-01        SPY          SIGNAL  2023-06-02 06:27:45\n"
     ]
    }
   ],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,asset_name,prediction_col,dtStr_imported] ],columns=[\"prediction_date\",\"asset_name\",\"prediction_name\",\"pred_timestamp\"])\n",
    "print(outputDF.info())\n",
    "print(outputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction_date': '2023-06-01',\n",
       "  'asset_name': 'SPY',\n",
       "  'prediction_name': 'SIGNAL',\n",
       "  'pred_timestamp': '2023-06-02 06:27:45',\n",
       "  'feature_for_prediction': [{'input_date': '2023-03-08',\n",
       "    'input_feature': -0.136},\n",
       "   {'input_date': '2023-03-09', 'input_feature': -0.3457},\n",
       "   {'input_date': '2023-03-10', 'input_feature': -0.6468},\n",
       "   {'input_date': '2023-03-13', 'input_feature': -0.9973},\n",
       "   {'input_date': '2023-03-14', 'input_feature': -1.2921},\n",
       "   {'input_date': '2023-03-15', 'input_feature': -1.5604},\n",
       "   {'input_date': '2023-03-16', 'input_feature': -1.7215},\n",
       "   {'input_date': '2023-03-17', 'input_feature': -1.868},\n",
       "   {'input_date': '2023-03-20', 'input_feature': -1.9535},\n",
       "   {'input_date': '2023-03-21', 'input_feature': -1.9351},\n",
       "   {'input_date': '2023-03-22', 'input_feature': -1.9198},\n",
       "   {'input_date': '2023-03-23', 'input_feature': -1.8915},\n",
       "   {'input_date': '2023-03-24', 'input_feature': -1.8243},\n",
       "   {'input_date': '2023-03-27', 'input_feature': -1.7229},\n",
       "   {'input_date': '2023-03-28', 'input_feature': -1.6103},\n",
       "   {'input_date': '2023-03-29', 'input_feature': -1.4299},\n",
       "   {'input_date': '2023-03-30', 'input_feature': -1.1858},\n",
       "   {'input_date': '2023-03-31', 'input_feature': -0.8479},\n",
       "   {'input_date': '2023-04-03', 'input_feature': -0.4465},\n",
       "   {'input_date': '2023-04-04', 'input_feature': -0.0469},\n",
       "   {'input_date': '2023-04-05', 'input_feature': 0.321},\n",
       "   {'input_date': '2023-04-06', 'input_feature': 0.6675},\n",
       "   {'input_date': '2023-04-10', 'input_feature': 0.9866},\n",
       "   {'input_date': '2023-04-11', 'input_feature': 1.2719},\n",
       "   {'input_date': '2023-04-12', 'input_feature': 1.5009},\n",
       "   {'input_date': '2023-04-13', 'input_feature': 1.7379},\n",
       "   {'input_date': '2023-04-14', 'input_feature': 1.9541},\n",
       "   {'input_date': '2023-04-17', 'input_feature': 2.1583},\n",
       "   {'input_date': '2023-04-18', 'input_feature': 2.3433},\n",
       "   {'input_date': '2023-04-19', 'input_feature': 2.5012},\n",
       "   {'input_date': '2023-04-20', 'input_feature': 2.6041},\n",
       "   {'input_date': '2023-04-21', 'input_feature': 2.6644},\n",
       "   {'input_date': '2023-04-24', 'input_feature': 2.6931},\n",
       "   {'input_date': '2023-04-25', 'input_feature': 2.6232},\n",
       "   {'input_date': '2023-04-26', 'input_feature': 2.4686},\n",
       "   {'input_date': '2023-04-27', 'input_feature': 2.3481},\n",
       "   {'input_date': '2023-04-28', 'input_feature': 2.2885},\n",
       "   {'input_date': '2023-05-01', 'input_feature': 2.2617},\n",
       "   {'input_date': '2023-05-02', 'input_feature': 2.202},\n",
       "   {'input_date': '2023-05-03', 'input_feature': 2.0886},\n",
       "   {'input_date': '2023-05-04', 'input_feature': 1.9099},\n",
       "   {'input_date': '2023-05-05', 'input_feature': 1.7745},\n",
       "   {'input_date': '2023-05-08', 'input_feature': 1.671},\n",
       "   {'input_date': '2023-05-09', 'input_feature': 1.5698},\n",
       "   {'input_date': '2023-05-10', 'input_feature': 1.4923},\n",
       "   {'input_date': '2023-05-11', 'input_feature': 1.4228},\n",
       "   {'input_date': '2023-05-12', 'input_feature': 1.353},\n",
       "   {'input_date': '2023-05-15', 'input_feature': 1.2986},\n",
       "   {'input_date': '2023-05-16', 'input_feature': 1.2242},\n",
       "   {'input_date': '2023-05-17', 'input_feature': 1.1916},\n",
       "   {'input_date': '2023-05-18', 'input_feature': 1.2283},\n",
       "   {'input_date': '2023-05-19', 'input_feature': 1.299},\n",
       "   {'input_date': '2023-05-22', 'input_feature': 1.3872},\n",
       "   {'input_date': '2023-05-23', 'input_feature': 1.4288},\n",
       "   {'input_date': '2023-05-24', 'input_feature': 1.4027},\n",
       "   {'input_date': '2023-05-25', 'input_feature': 1.3693},\n",
       "   {'input_date': '2023-05-26', 'input_feature': 1.3881},\n",
       "   {'input_date': '2023-05-30', 'input_feature': 1.4385},\n",
       "   {'input_date': '2023-05-31', 'input_feature': 0.6864},\n",
       "   {'input_date': '2023-06-01', 'input_feature': 0.8177}],\n",
       "  'prediction_result': [{'output_date': '2023-06-02',\n",
       "    'output_value': 0.3341284692},\n",
       "   {'output_date': '2023-06-05', 'output_value': -0.1997100413},\n",
       "   {'output_date': '2023-06-06', 'output_value': -0.7180367708},\n",
       "   {'output_date': '2023-06-07', 'output_value': -1.1303787231},\n",
       "   {'output_date': '2023-06-08', 'output_value': -1.3890806437},\n",
       "   {'output_date': '2023-06-09', 'output_value': -1.6210753918},\n",
       "   {'output_date': '2023-06-12', 'output_value': -1.8146314621},\n",
       "   {'output_date': '2023-06-13', 'output_value': -1.9654610157},\n",
       "   {'output_date': '2023-06-14', 'output_value': -2.0569782257},\n",
       "   {'output_date': '2023-06-15', 'output_value': -2.0673863888}]}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeature=dfFeature.reset_index()[[date_col,prediction_col]]\n",
    "    dataFeature[date_col]=dataFeature[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataFeature.columns=[\"input_date\",\"input_feature\"]\n",
    "    jsonFeature= json.loads(dataFeature.to_json(orient = 'records'))\n",
    "    item[\"feature_for_prediction\"]=jsonFeature\n",
    "    \n",
    "    dataPred=dfPrediction.reset_index()[[date_col,prediction_col]]\n",
    "    dataPred[date_col]=dataPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataPred.columns=[\"output_date\",\"output_value\"]\n",
    "    jsonPred= json.loads(dataPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonPred\n",
    " \n",
    "with open(\"fin_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.FinAssetForecast.fin_movement_forecast already exists.\n",
      "[SchemaField('prediction_result', 'RECORD', 'REPEATED', None, None, (SchemaField('output_value', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('output_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('prediction_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('feature_for_prediction', 'RECORD', 'REPEATED', None, None, (SchemaField('input_feature', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('input_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('pred_timestamp', 'TIMESTAMP', 'NULLABLE', None, None, (), None), SchemaField('prediction_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('asset_name', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "# schema=[  ]\n",
    ")\n",
    "\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e3a9e58-62e1-46cf-a25e-1774d45dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return   'completed job.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
