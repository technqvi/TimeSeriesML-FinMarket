{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "70cf04c4-e1ce-4eb2-b82c-8b98bae04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def forecast_asset_movement(request):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55257eb9-7ddb-4aa6-8d11-bc42344a6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Enviroment Variable\n",
      "2023-04-28 - SPY -EMA1\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "#name = request.args.get(\"today\", \"today\")\n",
    "#https://stackoverflow.com/questions/61573102/calling-a-google-cloud-function-from-within-python\n",
    "#https://medium.com/google-cloud/setup-and-invoke-cloud-functions-using-python-e801a8633096\n",
    "# print(\"JSON Info\") # Post Method\n",
    "# request_json = request.get_json()\n",
    "# print(request_json)\n",
    "\n",
    "# print(f\"TODAY Request :{request_json['TODAY']}\")\n",
    "# print(f\"ASSET Request :{request_json['ASSET']}\")\n",
    "# print(f\"PREDICTION Request :{request_json['PREDICTION']}\")\n",
    "print(\"==================================================\")\n",
    "\n",
    "# print(\"Value Info\")\n",
    "# print(request.values)\n",
    "\n",
    "print(\"Enviroment Variable\")\n",
    "today=os.environ.get('TODAY', '') \n",
    "#today=os.environ.get('TODAY', '2023-04-28')  \n",
    "asset_name=os.environ.get('ASSET', 'SPY')\n",
    "prediction_name=os.environ.get('PREDICTION','EMA1')\n",
    "print(f\"{today} - {asset_name} -{prediction_name}\")\n",
    "print(\"==================================================\")\n",
    "\n",
    "loadModelMode='gcs'   # local,gcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from gcs\n",
      "gs://demo-ts-forecast-pongthorn/model-ema1/EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\n",
      "gs://demo-ts-forecast-pongthorn/model-ema1/scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n",
      "gs://demo-ts-forecast-pongthorn/model-ema1/scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_file=\"EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\"\n",
    "scaler_file=\"scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\"\n",
    "scalerPred_file=\"scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\"\n",
    "\n",
    "if loadModelMode=='local':\n",
    " objectPaht=\"model/model-ema1\"\n",
    "else:\n",
    " objectPaht=\"gs://demo-ts-forecast-pongthorn/model-ema1\"   \n",
    "\n",
    "\n",
    "model_path=f\"{objectPaht}/{model_file}\"\n",
    "scale_input_path=f\"{objectPaht}/{scaler_file}\"\n",
    "scale_output_path=f\"{objectPaht}/{scalerPred_file}\"\n",
    "\n",
    "print(f\"load model from {loadModelMode}\")   \n",
    "print(model_path)\n",
    "print(scale_input_path)\n",
    "print(scale_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "443426bb-6329-48d8-9c1b-f5a51c31b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModelMode=='local':\n",
    "    try:\n",
    "        print(\"Model and Scaler Object Summary\")\n",
    "        x_model = load_model(model_path)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex)) \n",
    "    \n",
    "    try:\n",
    "        print(\"Scaler Max-Min\")\n",
    "        x_scaler = joblib.load(scale_input_path)\n",
    "        x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex))\n",
    "\n",
    "    print(\"=====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "205bf465-9f2b-417c-86aa-22a5062f4f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if loadModelMode=='gcs':\n",
    " try:    \n",
    "    gcs_client = storage.Client()\n",
    "\n",
    "    with open(scaler_file, 'wb') as scaler_f, open(scalerPred_file, 'wb') as scaler_pred_f,open(model_file, 'wb') as model_f:\n",
    "        gcs_client.download_blob_to_file(scale_input_path, scaler_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(scale_output_path, scaler_pred_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(model_path, model_f\n",
    "        )\n",
    "\n",
    "    x_scaler = joblib.load(scaler_file)\n",
    "    x_scalerPred=joblib.load(scalerPred_file)\n",
    "    x_model = load_model(model_file)\n",
    " except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4cbc6a3f-8264-4b1d-9424-34a3cf16177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 180)               131040    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 180)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1810      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,850\n",
      "Trainable params: 132,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n"
     ]
    }
   ],
   "source": [
    "print(x_model.summary())\n",
    "#(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-01 16:07:11\n"
     ]
    }
   ],
   "source": [
    "date_col='Date'\n",
    "prediction_col=prediction_name\n",
    "feature_cols=[prediction_name]\n",
    "\n",
    "input_sequence_length =60\n",
    "output_sequence_length =10\n",
    "\n",
    "nLastData=input_sequence_length*2\n",
    "\n",
    "colInput='feature'\n",
    "colOutput='prediction'\n",
    "\n",
    "\n",
    "# dt_imported=datetime.now()\n",
    "dt_imported=datetime.now(timezone.utc)\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358bfe0-03cf-4adb-b9e3-2c8724f406d3",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "229995b2-c8b7-4b62-b3f7-df62eb88b688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.FinAssetForecast.fin_movement_forecast\n",
      "pongthorn.FinAssetForecast.fin_data\n"
     ]
    }
   ],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='FinAssetForecast'\n",
    "table_id = f\"{projectId}.{dataset_id}.fin_movement_forecast\"\n",
    "table_data_id = f\"{projectId}.{dataset_id}.fin_data\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "\n",
    "# json_credential_file=r'C:\\Windows\\pongthorn-5decdc5124f5.json'\n",
    "# credentials = service_account.Credentials.from_service_account_file(json_credential_file)\n",
    "# client = bigquery.Client(project=projectId,credentials=credentials )\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b682d76-f7b1-45b2-92c1-78a5c0e7af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if today=='':\n",
    "    sqlLastDate=f\"\"\" select max(Date) as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \"\"\"\n",
    "    results = client.query(sqlLastDate)\n",
    "\n",
    "    for row in results:\n",
    "        lastDate=row['LastDate']    \n",
    "        if  lastDate == None:\n",
    "         raise Exception(f\"Not found price data  of {asset_name}\")\n",
    "        lastDate=lastDate.strftime('%Y-%m-%d')\n",
    "        \n",
    "\n",
    "    today=lastDate\n",
    "    print(f\"Last Price of  {asset_name} at {today}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d4835aad-60d9-4c16-b69e-7da926e9ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get last price of SPY\n",
      "select prediction_date,asset_name,prediction_name,pred_timestamp from `pongthorn.FinAssetForecast.fin_movement_forecast` \n",
      "where prediction_date='2023-04-28' and   asset_name='SPY'\n",
      "order by pred_timestamp \n",
      "\n",
      "SPY-EMA1 at 2023-04-28 has not been predicted price movement yet.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get last price of {asset_name}\")\n",
    "sqlLastPred=f\"\"\"select prediction_date,asset_name,prediction_name,pred_timestamp from `{table_id}` \n",
    "where prediction_date='{today}' and   asset_name='{asset_name}'\n",
    "order by pred_timestamp \n",
    "\"\"\"\n",
    "print(sqlLastPred)\n",
    "dfLastPred=load_data_bq(sqlLastPred)\n",
    "if dfLastPred.empty==False:\n",
    "   dfLastPred=dfLastPred.drop_duplicates(subset=['prediction_date','asset_name','prediction_name'],keep='last') \n",
    "   print(f\"{asset_name}-{prediction_col}-{today} has been predicted price movement\")\n",
    "   print(dfLastPred)\n",
    "   #return \"there is one record of prediction price movement\"\n",
    "else:\n",
    "   print(f\"{asset_name}-{prediction_col} at {today} has not been predicted price movement yet.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab61afa5-0cbd-46c9-895d-20ddcd23b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2022-12-29 - 2023-04-28 as input to forecast\n"
     ]
    }
   ],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT  *  FROM `pongthorn.FinAssetForecast.fin_data`  \n",
      "Where  Date between  DATE_SUB(DATE '2023-04-28', INTERVAL 120 DAY) \n",
      "and '2023-04-28' and Symbol='SPY' order by Date,ImportDateTime\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 83 entries, 2022-12-29 to 2023-04-28\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Symbol          83 non-null     object        \n",
      " 1   Close           83 non-null     float64       \n",
      " 2   EMA1            83 non-null     float64       \n",
      " 3   EMA2            83 non-null     float64       \n",
      " 4   MACD            83 non-null     float64       \n",
      " 5   SIGNAL          83 non-null     float64       \n",
      " 6   ImportDateTime  83 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "           Symbol   Close             ImportDateTime\n",
      "Date                                                \n",
      "2022-12-29    SPY  383.44 2023-06-01 06:44:32.649830\n",
      "2022-12-30    SPY  382.43 2023-06-01 06:44:32.649830\n",
      "2023-01-03    SPY  380.82 2023-06-01 06:44:32.649830\n",
      "2023-01-04    SPY  383.76 2023-06-01 06:44:32.649830\n",
      "2023-01-05    SPY  379.38 2023-06-01 06:44:32.649830\n",
      "           Symbol   Close             ImportDateTime\n",
      "Date                                                \n",
      "2023-04-24    SPY  412.63 2023-06-01 06:44:32.649830\n",
      "2023-04-25    SPY  406.08 2023-06-01 06:44:32.649830\n",
      "2023-04-26    SPY  404.36 2023-06-01 06:44:32.649830\n",
      "2023-04-27    SPY  412.41 2023-06-01 06:44:32.649830\n",
      "2023-04-28    SPY  415.93 2023-06-01 06:44:32.649830\n"
     ]
    }
   ],
   "source": [
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB(DATE '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}' and Symbol='{asset_name}' order by {date_col},ImportDateTime\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df=df.drop_duplicates(subset=[date_col,'Symbol'],keep='last')\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].head())\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    # return \"no enough data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(2, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[['Close','EMA1','EMA2']])\n",
    "# plt.ylabel('Price & EMA')\n",
    "\n",
    "# ax2 = plt.subplot(2, 1, 2)\n",
    "# plt.plot(df[['MACD','SIGNAL']])\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('MACD & Signal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Feature to Predict : EMA1 \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 60 entries, 2023-02-02 to 2023-04-28\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   EMA1    60 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 960.0 bytes\n",
      "None\n",
      "(60, 1)\n",
      "                EMA1\n",
      "Date                \n",
      "2023-02-02  405.0492\n",
      "2023-02-03  406.3766\n",
      "2023-02-06  407.0045\n",
      "2023-02-07  408.4928\n",
      "2023-02-08  408.8850\n",
      "                EMA1\n",
      "Date                \n",
      "2023-04-24  411.6727\n",
      "2023-04-25  410.6558\n",
      "2023-04-26  409.5111\n",
      "2023-04-27  410.0382\n",
      "2023-04-28  411.1094\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(5))\n",
    "print(dfForPred.tail(5))\n",
    "\n",
    "# dfForPred.plot(figsize = (20, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction as Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n",
      "[[0.78279087]\n",
      " [0.77924643]\n",
      " [0.77525654]\n",
      " [0.77709376]\n",
      " [0.78082747]]\n",
      "(1, 60, 1)\n",
      "1/1 [==============================] - 1s 618ms/step\n",
      "(1, 10) [[0.7905762  0.78114295 0.78453165 0.78248376 0.7993977  0.78919804\n",
      "  0.7891088  0.79289156 0.7923099  0.79277563]]\n",
      "(10, 1) [[413.90634]\n",
      " [411.19992]\n",
      " [412.17212]\n",
      " [411.5846 ]\n",
      " [416.43723]\n",
      " [413.51093]\n",
      " [413.48532]\n",
      " [414.5706 ]\n",
      " [414.40372]\n",
      " [414.53735]]\n",
      "============================Summary============================\n",
      "(60, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "print(xScaled[-5:])\n",
    "\n",
    "# # Way1\n",
    "# xScaledToPredict = []\n",
    "# xScaledToPredict.append(xScaled)\n",
    "# print(len(xScaledToPredict))\n",
    "\n",
    "# yPredScaled=x_model.predict(np.array(xScaledToPredict))\n",
    "# print(yPredScaled.shape,yPredScaled)\n",
    "\n",
    "# yPred  = x_scalerPred.inverse_transform(yPredScaled.reshape(-1, 1))\n",
    "# print(yPred.shape,yPred)\n",
    "\n",
    "#Way2\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "# print(\"============================Input============================\")\n",
    "# print(xUnscaled)\n",
    "# print(\"============================Output============================\")\n",
    "# print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Predition Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2)\n",
      "                EMA1     Type\n",
      "Date                         \n",
      "2023-02-02  405.0492  feature\n",
      "2023-02-03  406.3766  feature\n",
      "2023-02-06  407.0045  feature\n",
      "2023-02-07  408.4928  feature\n",
      "2023-02-08  408.8850  feature\n",
      "                EMA1     Type\n",
      "Date                         \n",
      "2023-04-24  411.6727  feature\n",
      "2023-04-25  410.6558  feature\n",
      "2023-04-26  409.5111  feature\n",
      "2023-04-27  410.0382  feature\n",
      "2023-04-28  411.1094  feature\n"
     ]
    }
   ],
   "source": [
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "dfFeature['Type']=colInput\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-05-01', '2023-05-02', '2023-05-03', '2023-05-04',\n",
      "               '2023-05-05', '2023-05-08', '2023-05-09', '2023-05-10',\n",
      "               '2023-05-11', '2023-05-12'],\n",
      "              dtype='datetime64[ns]', freq='B')\n",
      "(10, 2)\n",
      "                  EMA1        Type\n",
      "Date                              \n",
      "2023-05-01  413.906342  prediction\n",
      "2023-05-02  411.199921  prediction\n",
      "2023-05-03  412.172119  prediction\n",
      "2023-05-04  411.584595  prediction\n",
      "2023-05-05  416.437225  prediction\n",
      "2023-05-08  413.510925  prediction\n",
      "2023-05-09  413.485321  prediction\n",
      "2023-05-10  414.570587  prediction\n",
      "2023-05-11  414.403717  prediction\n",
      "2023-05-12  414.537354  prediction\n"
     ]
    }
   ],
   "source": [
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq='b',periods=output_sequence_length)\n",
    "print(datePred)\n",
    "\n",
    "dfPrediction=pd.DataFrame(data= yPred,columns=feature_cols,index=datePred)\n",
    "dfPrediction.index.name=date_col\n",
    "dfPrediction['Type']=colOutput\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   prediction_date  1 non-null      object\n",
      " 1   asset_name       1 non-null      object\n",
      " 2   prediction_name  1 non-null      object\n",
      " 3   pred_timestamp   1 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 160.0+ bytes\n",
      "None\n",
      "  prediction_date asset_name prediction_name       pred_timestamp\n",
      "0      2023-04-28        SPY            EMA1  2023-06-01 16:07:11\n"
     ]
    }
   ],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,asset_name,prediction_col,dtStr_imported] ],columns=[\"prediction_date\",\"asset_name\",\"prediction_name\",\"pred_timestamp\"])\n",
    "print(outputDF.info())\n",
    "print(outputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction_date': '2023-04-28',\n",
       "  'asset_name': 'SPY',\n",
       "  'prediction_name': 'EMA1',\n",
       "  'pred_timestamp': '2023-06-01 16:07:11',\n",
       "  'feature_for_prediction': [{'input_date': '2023-02-02',\n",
       "    'input_feature': 405.0492},\n",
       "   {'input_date': '2023-02-03', 'input_feature': 406.3766},\n",
       "   {'input_date': '2023-02-06', 'input_feature': 407.0045},\n",
       "   {'input_date': '2023-02-07', 'input_feature': 408.4928},\n",
       "   {'input_date': '2023-02-08', 'input_feature': 408.885},\n",
       "   {'input_date': '2023-02-09', 'input_feature': 408.5586},\n",
       "   {'input_date': '2023-02-10', 'input_feature': 408.4643},\n",
       "   {'input_date': '2023-02-13', 'input_feature': 409.2581},\n",
       "   {'input_date': '2023-02-14', 'input_feature': 409.873},\n",
       "   {'input_date': '2023-02-15', 'input_feature': 410.6197},\n",
       "   {'input_date': '2023-02-16', 'input_feature': 410.1943},\n",
       "   {'input_date': '2023-02-17', 'input_feature': 409.6608},\n",
       "   {'input_date': '2023-02-21', 'input_feature': 407.7388},\n",
       "   {'input_date': '2023-02-22', 'input_feature': 406.0663},\n",
       "   {'input_date': '2023-02-23', 'input_feature': 405.0834},\n",
       "   {'input_date': '2023-02-24', 'input_feature': 403.5009},\n",
       "   {'input_date': '2023-02-27', 'input_feature': 402.4517},\n",
       "   {'input_date': '2023-02-28', 'input_feature': 401.3259},\n",
       "   {'input_date': '2023-03-01', 'input_feature': 400.1285},\n",
       "   {'input_date': '2023-03-02', 'input_feature': 399.7069},\n",
       "   {'input_date': '2023-03-03', 'input_feature': 400.522},\n",
       "   {'input_date': '2023-03-06', 'input_feature': 401.2398},\n",
       "   {'input_date': '2023-03-07', 'input_feature': 400.6999},\n",
       "   {'input_date': '2023-03-08', 'input_feature': 400.3763},\n",
       "   {'input_date': '2023-03-09', 'input_feature': 398.7733},\n",
       "   {'input_date': '2023-03-10', 'input_feature': 396.4345},\n",
       "   {'input_date': '2023-03-13', 'input_feature': 394.421},\n",
       "   {'input_date': '2023-03-14', 'input_feature': 393.9317},\n",
       "   {'input_date': '2023-03-15', 'input_feature': 393.0859},\n",
       "   {'input_date': '2023-03-16', 'input_feature': 393.6358},\n",
       "   {'input_date': '2023-03-17', 'input_feature': 392.9729},\n",
       "   {'input_date': '2023-03-20', 'input_feature': 393.1124},\n",
       "   {'input_date': '2023-03-21', 'input_feature': 394.1665},\n",
       "   {'input_date': '2023-03-22', 'input_feature': 393.7926},\n",
       "   {'input_date': '2023-03-23', 'input_feature': 393.6794},\n",
       "   {'input_date': '2023-03-24', 'input_feature': 394.0559},\n",
       "   {'input_date': '2023-03-27', 'input_feature': 394.4984},\n",
       "   {'input_date': '2023-03-28', 'input_feature': 394.6987},\n",
       "   {'input_date': '2023-03-29', 'input_feature': 395.908},\n",
       "   {'input_date': '2023-03-30', 'input_feature': 397.3248},\n",
       "   {'input_date': '2023-03-31', 'input_feature': 399.5184},\n",
       "   {'input_date': '2023-04-03', 'input_feature': 401.5969},\n",
       "   {'input_date': '2023-04-04', 'input_feature': 402.8829},\n",
       "   {'input_date': '2023-04-05', 'input_feature': 403.7406},\n",
       "   {'input_date': '2023-04-06', 'input_feature': 404.7314},\n",
       "   {'input_date': '2023-04-10', 'input_feature': 405.6184},\n",
       "   {'input_date': '2023-04-11', 'input_feature': 406.3641},\n",
       "   {'input_date': '2023-04-12', 'input_feature': 406.6707},\n",
       "   {'input_date': '2023-04-13', 'input_feature': 407.9069},\n",
       "   {'input_date': '2023-04-14', 'input_feature': 408.7347},\n",
       "   {'input_date': '2023-04-17', 'input_feature': 409.6812},\n",
       "   {'input_date': '2023-04-18', 'input_feature': 410.5046},\n",
       "   {'input_date': '2023-04-19', 'input_feature': 411.1656},\n",
       "   {'input_date': '2023-04-20', 'input_feature': 411.2955},\n",
       "   {'input_date': '2023-04-21', 'input_feature': 411.4599},\n",
       "   {'input_date': '2023-04-24', 'input_feature': 411.6727},\n",
       "   {'input_date': '2023-04-25', 'input_feature': 410.6558},\n",
       "   {'input_date': '2023-04-26', 'input_feature': 409.5111},\n",
       "   {'input_date': '2023-04-27', 'input_feature': 410.0382},\n",
       "   {'input_date': '2023-04-28', 'input_feature': 411.1094}],\n",
       "  'prediction_result': [{'output_date': '2023-05-01',\n",
       "    'output_value': 413.9063415527},\n",
       "   {'output_date': '2023-05-02', 'output_value': 411.1999206543},\n",
       "   {'output_date': '2023-05-03', 'output_value': 412.1721191406},\n",
       "   {'output_date': '2023-05-04', 'output_value': 411.5845947266},\n",
       "   {'output_date': '2023-05-05', 'output_value': 416.4372253418},\n",
       "   {'output_date': '2023-05-08', 'output_value': 413.510925293},\n",
       "   {'output_date': '2023-05-09', 'output_value': 413.4853210449},\n",
       "   {'output_date': '2023-05-10', 'output_value': 414.5705871582},\n",
       "   {'output_date': '2023-05-11', 'output_value': 414.403717041},\n",
       "   {'output_date': '2023-05-12', 'output_value': 414.5373535156}]}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeature=dfFeature.reset_index()[[date_col,prediction_col]]\n",
    "    dataFeature[date_col]=dataFeature[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataFeature.columns=[\"input_date\",\"input_feature\"]\n",
    "    jsonFeature= json.loads(dataFeature.to_json(orient = 'records'))\n",
    "    item[\"feature_for_prediction\"]=jsonFeature\n",
    "    \n",
    "    dataPred=dfPrediction.reset_index()[[date_col,prediction_col]]\n",
    "    dataPred[date_col]=dataPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataPred.columns=[\"output_date\",\"output_value\"]\n",
    "    jsonPred= json.loads(dataPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonPred\n",
    " \n",
    "with open(\"fin_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.FinAssetForecast.fin_movement_forecast already exists.\n",
      "[SchemaField('prediction_result', 'RECORD', 'REPEATED', None, None, (SchemaField('output_value', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('output_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('prediction_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('feature_for_prediction', 'RECORD', 'REPEATED', None, None, (SchemaField('input_feature', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('input_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('pred_timestamp', 'TIMESTAMP', 'NULLABLE', None, None, (), None), SchemaField('prediction_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('asset_name', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "# schema=[  ]\n",
    ")\n",
    "\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8e3a9e58-62e1-46cf-a25e-1774d45dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return   'completed job.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
