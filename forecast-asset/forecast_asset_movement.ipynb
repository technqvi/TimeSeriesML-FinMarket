{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-use-google-cloud-function-with-python/\n",
    "#https://medium.com/google-cloud/setup-and-invoke-cloud-functions-using-python-e801a8633096\n",
    "#https://codelabs.developers.google.com/codelabs/cloud-functions-python-http#6\n",
    "#https://stackoverflow.com/questions/61573102/calling-a-google-cloud-function-from-within-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70cf04c4-e1ce-4eb2-b82c-8b98bae04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def forecast_asset_movement(request):\n",
    "\n",
    "#name = request.args.get(\"today\", \"today\")\n",
    "# if   request is not None:  \n",
    "#     today=request[\"today\"]\n",
    "#     asset_name=request[\"asset_name\"]\n",
    "#     prediction_name=request[\"prediction_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "today='2023-04-28'\n",
    "asset_name=\"SPY\"\n",
    "prediction_name='EMA1'\n",
    "\n",
    "model_path=\"model/model-ema1/EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\"\n",
    "scale_input_path=\"model/model-ema1/scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\"\n",
    "scale_output_path=\"model/model-ema1/scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\"\n",
    "\n",
    "# model_path=\"gs://demo-ts-forecast-pongthorn/model-ema1/EMA1_60To10_SPY_E150S20-Y2015-2023_ma.h5\"\n",
    "# scale_input_path=\"gs://demo-ts-forecast-pongthorn/model-ema1/scaler_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\"\n",
    "# scale_output_path=\"gs://demo-ts-forecast-pongthorn/model-ema1/scaler_pred_EMA1_60To10_SPY_E150S20-Y2015-2023.gz\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-31 02:07:27\n"
     ]
    }
   ],
   "source": [
    "date_col='Date'\n",
    "prediction_col=prediction_name\n",
    "feature_cols=[prediction_name]\n",
    "\n",
    "input_sequence_length =60\n",
    "output_sequence_length =10\n",
    "\n",
    "nLastData=input_sequence_length*2\n",
    "\n",
    "colInput='feature'\n",
    "colOutput='prediction'\n",
    "\n",
    "\n",
    "dt_imported=datetime.now()\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "443426bb-6329-48d8-9c1b-f5a51c31b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model and scaler - EMA1\n",
      "Model and Scaler Object Summary\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 180)               131040    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 180)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1810      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 132,850\n",
      "Trainable params: 132,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Scaler Max-Min\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n",
      "max=[473.99] and min=[187.09] and scale=[0.00348554]\n",
      "=====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(f\"Load model and scaler - {prediction_name}\")\n",
    "\n",
    "try:\n",
    "    print(\"Model and Scaler Object Summary\")\n",
    "    x_model = load_model(model_path)\n",
    "    print(x_model.summary())\n",
    "except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n",
    "    \n",
    "try:\n",
    "    print(\"Scaler Max-Min\")\n",
    "    x_scaler = joblib.load(scale_input_path)\n",
    "    x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "    #(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "    print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "    print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")\n",
    "    \n",
    "except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n",
    "    \n",
    "\n",
    "print(\"=====================================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358bfe0-03cf-4adb-b9e3-2c8724f406d3",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "229995b2-c8b7-4b62-b3f7-df62eb88b688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.FinAssetForecast.fin_movement_forecast\n",
      "pongthorn.FinAssetForecast.fin_data\n"
     ]
    }
   ],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='FinAssetForecast'\n",
    "table_id = f\"{projectId}.{dataset_id}.fin_movement_forecast\"\n",
    "table_data_id = f\"{projectId}.{dataset_id}.fin_data\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "\n",
    "# json_credential_file=r'C:\\Windows\\pongthorn-5decdc5124f5.json'\n",
    "# credentials = service_account.Credentials.from_service_account_file(json_credential_file)\n",
    "# client = bigquery.Client(project=projectId,credentials=credentials )\n",
    "client = bigquery.Client(project=projectId )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab61afa5-0cbd-46c9-895d-20ddcd23b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2022-12-29 - 2023-04-28 as input to forecast\n"
     ]
    }
   ],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT  *  FROM `pongthorn.FinAssetForecast.fin_data`  \n",
      "Where  Date between  DATE_SUB(DATE '2023-04-28', INTERVAL 120 DAY) \n",
      "and '2023-04-28' and Symbol='SPY' order by Date\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 81 entries, 2023-01-03 to 2023-04-28\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Symbol          81 non-null     object        \n",
      " 1   Close           81 non-null     float64       \n",
      " 2   EMA1            81 non-null     float64       \n",
      " 3   EMA2            81 non-null     float64       \n",
      " 4   MACD            81 non-null     float64       \n",
      " 5   SIGNAL          81 non-null     float64       \n",
      " 6   ImportDateTime  81 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 5.1+ KB\n",
      "None\n",
      "           Symbol   Close      EMA1      EMA2    MACD  SIGNAL  \\\n",
      "Date                                                            \n",
      "2023-01-03    SPY  380.82  380.8200  380.8200  0.0000  0.0000   \n",
      "2023-01-04    SPY  383.76  381.3545  381.1000  0.2545  0.0318   \n",
      "2023-01-05    SPY  379.38  380.9955  380.9362  0.0593  0.0353   \n",
      "2023-01-06    SPY  388.08  382.2836  381.6166  0.6671  0.1142   \n",
      "2023-01-09    SPY  387.86  383.2975  382.2112  1.0863  0.2357   \n",
      "\n",
      "                       ImportDateTime  \n",
      "Date                                   \n",
      "2023-01-03 2023-05-30 14:16:23.180225  \n",
      "2023-01-04 2023-05-30 14:16:23.180225  \n",
      "2023-01-05 2023-05-30 14:16:23.180225  \n",
      "2023-01-06 2023-05-30 14:16:23.180225  \n",
      "2023-01-09 2023-05-30 14:16:23.180225  \n",
      "           Symbol   Close      EMA1      EMA2    MACD  SIGNAL  \\\n",
      "Date                                                            \n",
      "2023-04-24    SPY  412.63  411.6727  408.7760  2.8967  2.7027   \n",
      "2023-04-25    SPY  406.08  410.6558  408.5192  2.1366  2.6319   \n",
      "2023-04-26    SPY  404.36  409.5111  408.1231  1.3880  2.4765   \n",
      "2023-04-27    SPY  412.41  410.0382  408.5314  1.5068  2.3552   \n",
      "2023-04-28    SPY  415.93  411.1094  409.2360  1.8734  2.2950   \n",
      "\n",
      "                       ImportDateTime  \n",
      "Date                                   \n",
      "2023-04-24 2023-05-30 14:16:23.180225  \n",
      "2023-04-25 2023-05-30 14:16:23.180225  \n",
      "2023-04-26 2023-05-30 14:16:23.180225  \n",
      "2023-04-27 2023-05-30 14:16:23.180225  \n",
      "2023-04-28 2023-05-30 14:16:23.180225  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB(DATE '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}' and Symbol='{asset_name}' order by {date_col}\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    # return \"no enough data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplots(2, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[['Close','EMA1','EMA2']])\n",
    "# plt.ylabel('Price & EMA')\n",
    "\n",
    "# ax2 = plt.subplot(2, 1, 2)\n",
    "# plt.plot(df[['MACD','SIGNAL']])\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('MACD & Signal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Feature to Predict : EMA1 \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 60 entries, 2023-02-02 to 2023-04-28\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   EMA1    60 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 960.0 bytes\n",
      "None\n",
      "(60, 1)\n",
      "                EMA1\n",
      "Date                \n",
      "2023-02-02  405.0143\n",
      "2023-02-03  406.3481\n",
      "2023-02-06  406.9812\n",
      "2023-02-07  408.4737\n",
      "2023-02-08  408.8694\n",
      "                EMA1\n",
      "Date                \n",
      "2023-04-24  411.6727\n",
      "2023-04-25  410.6558\n",
      "2023-04-26  409.5111\n",
      "2023-04-27  410.0382\n",
      "2023-04-28  411.1094\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(5))\n",
    "print(dfForPred.tail(5))\n",
    "\n",
    "# dfForPred.plot(figsize = (20, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n",
      "[[0.78279087]\n",
      " [0.77924643]\n",
      " [0.77525654]\n",
      " [0.77709376]\n",
      " [0.78082747]]\n",
      "(1, 60, 1)\n",
      "1/1 [==============================] - 1s 565ms/step\n",
      "(1, 10) [[0.7905763  0.7811429  0.7845317  0.78248376 0.7993978  0.78919804\n",
      "  0.78910875 0.7928916  0.7923099  0.7927757 ]]\n",
      "(10, 1) [[413.90634]\n",
      " [411.1999 ]\n",
      " [412.17215]\n",
      " [411.5846 ]\n",
      " [416.43726]\n",
      " [413.51093]\n",
      " [413.48532]\n",
      " [414.57062]\n",
      " [414.40372]\n",
      " [414.53735]]\n",
      "============================Summary============================\n",
      "(60, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "print(xScaled[-5:])\n",
    "\n",
    "# # Way1\n",
    "# xScaledToPredict = []\n",
    "# xScaledToPredict.append(xScaled)\n",
    "# print(len(xScaledToPredict))\n",
    "\n",
    "# yPredScaled=x_model.predict(np.array(xScaledToPredict))\n",
    "# print(yPredScaled.shape,yPredScaled)\n",
    "\n",
    "# yPred  = x_scalerPred.inverse_transform(yPredScaled.reshape(-1, 1))\n",
    "# print(yPred.shape,yPred)\n",
    "\n",
    "#Way2\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "# print(\"============================Input============================\")\n",
    "# print(xUnscaled)\n",
    "# print(\"============================Output============================\")\n",
    "# print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Predition Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2)\n",
      "                EMA1     Type\n",
      "Date                         \n",
      "2023-02-02  405.0143  feature\n",
      "2023-02-03  406.3481  feature\n",
      "2023-02-06  406.9812  feature\n",
      "2023-02-07  408.4737  feature\n",
      "2023-02-08  408.8694  feature\n",
      "                EMA1     Type\n",
      "Date                         \n",
      "2023-04-24  411.6727  feature\n",
      "2023-04-25  410.6558  feature\n",
      "2023-04-26  409.5111  feature\n",
      "2023-04-27  410.0382  feature\n",
      "2023-04-28  411.1094  feature\n"
     ]
    }
   ],
   "source": [
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "dfFeature['Type']=colInput\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-05-01', '2023-05-02', '2023-05-03', '2023-05-04',\n",
      "               '2023-05-05', '2023-05-08', '2023-05-09', '2023-05-10',\n",
      "               '2023-05-11', '2023-05-12'],\n",
      "              dtype='datetime64[ns]', freq='B')\n",
      "(10, 2)\n",
      "                  EMA1        Type\n",
      "Date                              \n",
      "2023-05-01  413.906342  prediction\n",
      "2023-05-02  411.199890  prediction\n",
      "2023-05-03  412.172150  prediction\n",
      "2023-05-04  411.584595  prediction\n",
      "2023-05-05  416.437256  prediction\n",
      "2023-05-08  413.510925  prediction\n",
      "2023-05-09  413.485321  prediction\n",
      "2023-05-10  414.570618  prediction\n",
      "2023-05-11  414.403717  prediction\n",
      "2023-05-12  414.537354  prediction\n"
     ]
    }
   ],
   "source": [
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq='b',periods=output_sequence_length)\n",
    "print(datePred)\n",
    "\n",
    "dfPrediction=pd.DataFrame(data= yPred,columns=feature_cols,index=datePred)\n",
    "dfPrediction.index.name=date_col\n",
    "dfPrediction['Type']=colOutput\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   prediction_date  1 non-null      object\n",
      " 1   asset_name       1 non-null      object\n",
      " 2   prediction_name  1 non-null      object\n",
      " 3   pred_timestamp   1 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 160.0+ bytes\n",
      "None\n",
      "  prediction_date asset_name prediction_name       pred_timestamp\n",
      "0      2023-04-28        SPY            EMA1  2023-05-31 02:07:27\n"
     ]
    }
   ],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,asset_name,prediction_col,dtStr_imported] ],columns=[\"prediction_date\",\"asset_name\",\"prediction_name\",\"pred_timestamp\"])\n",
    "print(outputDF.info())\n",
    "print(outputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction_date': '2023-04-28',\n",
       "  'asset_name': 'SPY',\n",
       "  'prediction_name': 'EMA1',\n",
       "  'pred_timestamp': '2023-05-31 02:07:27',\n",
       "  'feature_for_prediction': [{'input_date': '2023-02-02',\n",
       "    'input_feature': 405.0143},\n",
       "   {'input_date': '2023-02-03', 'input_feature': 406.3481},\n",
       "   {'input_date': '2023-02-06', 'input_feature': 406.9812},\n",
       "   {'input_date': '2023-02-07', 'input_feature': 408.4737},\n",
       "   {'input_date': '2023-02-08', 'input_feature': 408.8694},\n",
       "   {'input_date': '2023-02-09', 'input_feature': 408.5459},\n",
       "   {'input_date': '2023-02-10', 'input_feature': 408.4539},\n",
       "   {'input_date': '2023-02-13', 'input_feature': 409.2495},\n",
       "   {'input_date': '2023-02-14', 'input_feature': 409.866},\n",
       "   {'input_date': '2023-02-15', 'input_feature': 410.614},\n",
       "   {'input_date': '2023-02-16', 'input_feature': 410.1896},\n",
       "   {'input_date': '2023-02-17', 'input_feature': 409.657},\n",
       "   {'input_date': '2023-02-21', 'input_feature': 407.7357},\n",
       "   {'input_date': '2023-02-22', 'input_feature': 406.0638},\n",
       "   {'input_date': '2023-02-23', 'input_feature': 405.0813},\n",
       "   {'input_date': '2023-02-24', 'input_feature': 403.4992},\n",
       "   {'input_date': '2023-02-27', 'input_feature': 402.4503},\n",
       "   {'input_date': '2023-02-28', 'input_feature': 401.3248},\n",
       "   {'input_date': '2023-03-01', 'input_feature': 400.1275},\n",
       "   {'input_date': '2023-03-02', 'input_feature': 399.7062},\n",
       "   {'input_date': '2023-03-03', 'input_feature': 400.5214},\n",
       "   {'input_date': '2023-03-06', 'input_feature': 401.2393},\n",
       "   {'input_date': '2023-03-07', 'input_feature': 400.6995},\n",
       "   {'input_date': '2023-03-08', 'input_feature': 400.3759},\n",
       "   {'input_date': '2023-03-09', 'input_feature': 398.773},\n",
       "   {'input_date': '2023-03-10', 'input_feature': 396.4343},\n",
       "   {'input_date': '2023-03-13', 'input_feature': 394.4208},\n",
       "   {'input_date': '2023-03-14', 'input_feature': 393.9315},\n",
       "   {'input_date': '2023-03-15', 'input_feature': 393.0858},\n",
       "   {'input_date': '2023-03-16', 'input_feature': 393.6357},\n",
       "   {'input_date': '2023-03-17', 'input_feature': 392.9728},\n",
       "   {'input_date': '2023-03-20', 'input_feature': 393.1123},\n",
       "   {'input_date': '2023-03-21', 'input_feature': 394.1664},\n",
       "   {'input_date': '2023-03-22', 'input_feature': 393.7925},\n",
       "   {'input_date': '2023-03-23', 'input_feature': 393.6793},\n",
       "   {'input_date': '2023-03-24', 'input_feature': 394.0558},\n",
       "   {'input_date': '2023-03-27', 'input_feature': 394.4984},\n",
       "   {'input_date': '2023-03-28', 'input_feature': 394.6987},\n",
       "   {'input_date': '2023-03-29', 'input_feature': 395.908},\n",
       "   {'input_date': '2023-03-30', 'input_feature': 397.3247},\n",
       "   {'input_date': '2023-03-31', 'input_feature': 399.5184},\n",
       "   {'input_date': '2023-04-03', 'input_feature': 401.5969},\n",
       "   {'input_date': '2023-04-04', 'input_feature': 402.8829},\n",
       "   {'input_date': '2023-04-05', 'input_feature': 403.7406},\n",
       "   {'input_date': '2023-04-06', 'input_feature': 404.7314},\n",
       "   {'input_date': '2023-04-10', 'input_feature': 405.6184},\n",
       "   {'input_date': '2023-04-11', 'input_feature': 406.3641},\n",
       "   {'input_date': '2023-04-12', 'input_feature': 406.6707},\n",
       "   {'input_date': '2023-04-13', 'input_feature': 407.9069},\n",
       "   {'input_date': '2023-04-14', 'input_feature': 408.7347},\n",
       "   {'input_date': '2023-04-17', 'input_feature': 409.6812},\n",
       "   {'input_date': '2023-04-18', 'input_feature': 410.5046},\n",
       "   {'input_date': '2023-04-19', 'input_feature': 411.1656},\n",
       "   {'input_date': '2023-04-20', 'input_feature': 411.2955},\n",
       "   {'input_date': '2023-04-21', 'input_feature': 411.4599},\n",
       "   {'input_date': '2023-04-24', 'input_feature': 411.6727},\n",
       "   {'input_date': '2023-04-25', 'input_feature': 410.6558},\n",
       "   {'input_date': '2023-04-26', 'input_feature': 409.5111},\n",
       "   {'input_date': '2023-04-27', 'input_feature': 410.0382},\n",
       "   {'input_date': '2023-04-28', 'input_feature': 411.1094}],\n",
       "  'prediction_result': [{'output_date': '2023-05-01',\n",
       "    'output_value': 413.9063415527},\n",
       "   {'output_date': '2023-05-02', 'output_value': 411.1998901367},\n",
       "   {'output_date': '2023-05-03', 'output_value': 412.1721496582},\n",
       "   {'output_date': '2023-05-04', 'output_value': 411.5845947266},\n",
       "   {'output_date': '2023-05-05', 'output_value': 416.4372558594},\n",
       "   {'output_date': '2023-05-08', 'output_value': 413.510925293},\n",
       "   {'output_date': '2023-05-09', 'output_value': 413.4853210449},\n",
       "   {'output_date': '2023-05-10', 'output_value': 414.5706176758},\n",
       "   {'output_date': '2023-05-11', 'output_value': 414.403717041},\n",
       "   {'output_date': '2023-05-12', 'output_value': 414.5373535156}]}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeature=dfFeature.reset_index()[[date_col,prediction_col]]\n",
    "    dataFeature[date_col]=dataFeature[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataFeature.columns=[\"input_date\",\"input_feature\"]\n",
    "    jsonFeature= json.loads(dataFeature.to_json(orient = 'records'))\n",
    "    item[\"feature_for_prediction\"]=jsonFeature\n",
    "    \n",
    "    dataPred=dfPrediction.reset_index()[[date_col,prediction_col]]\n",
    "    dataPred[date_col]=dataPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataPred.columns=[\"output_date\",\"output_value\"]\n",
    "    jsonPred= json.loads(dataPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonPred\n",
    " \n",
    "with open(\"fin_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.FinAssetForecast.fin_movement_forecast already exists.\n",
      "[SchemaField('prediction_result', 'RECORD', 'REPEATED', None, None, (SchemaField('output_value', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('output_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('prediction_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('feature_for_prediction', 'RECORD', 'REPEATED', None, None, (SchemaField('input_feature', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('input_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('pred_timestamp', 'TIMESTAMP', 'NULLABLE', None, None, (), None), SchemaField('prediction_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('asset_name', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "# schema=[  ]\n",
    ")\n",
    "\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e3a9e58-62e1-46cf-a25e-1774d45dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return   'completed job.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31b11f33-37d0-4b34-b264-e6231bf4cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # indent method\n",
    "# # uncomment both return statement\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "# start_pred_date='2023-04-28'  # to make predictoin of 02 May 23\n",
    "# table_date_id=\"pongthorn.FinAssetForecast.fin_data\"\n",
    "# asset_name='SPY'\n",
    "# prediction_name='EMA1'\n",
    "\n",
    "# projectId='pongthorn'\n",
    "# json_credential_file=r'C:\\Windows\\pongthorn-5decdc5124f5.json'\n",
    "# credentials = service_account.Credentials.from_service_account_file(json_credential_file)\n",
    "# client = bigquery.Client(project=projectId,credentials=credentials )\n",
    "\n",
    "# sqlXYZ=f\"\"\"\n",
    "# SELECT  Date  FROM `{table_data_id}`  \n",
    "# Where  Date >= '{start_pred_date}' and Symbol='{asset}' order by Date\n",
    "# \"\"\"\n",
    "# print(sqlXYZ)\n",
    "# query_result=client.query(sqlXYZ)\n",
    "# dfXYZ=query_result.to_dataframe()\n",
    "\n",
    "# for idx,row in dfXYZ.iterrows():\n",
    "#     x_day=row[\"Date\"]\n",
    "#     request_data={\"today\":x_day.strftime('%Y-%m-%d'),\"asset_name\":asset_name,\"prediction_name\":prediction_name}\n",
    "#     print(f\"Predict data  with {request_data}\")  \n",
    "#     # result=forecast_asset_movement(request_data) \n",
    "#     # print(result)\n",
    "#     print(f\"========================================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
