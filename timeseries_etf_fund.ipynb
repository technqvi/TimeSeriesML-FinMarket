{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a33b330-1683-406a-ac98-ab06b056554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from datetime import date, timedelta, datetime \n",
    "import time\n",
    "#https://keras.io/examples/timeseries/timeseries_weather_forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44cc18f7-f129-487d-8885-31c6db70ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_path = \"data/SPY-Daily-Y09-Now.csv\"\n",
    "asset_name='SP500'\n",
    "date_col='Date'\n",
    "# feature_cols=['EMA1', 'EMA2', 'MACD', 'RSI']\n",
    "feature_cols=['EMA1','MACD', 'RSI']\n",
    "target_col_index=0  # specigy index from feature_cols\n",
    "\n",
    "start_date='2022-01-01'\n",
    "end_date='2022-12-31'\n",
    "\n",
    "main_obj_metric='mean_absolute_error'\n",
    "main_loss='mean_absolute_error'\n",
    "\n",
    "split_fraction = 0.8\n",
    "\n",
    "\n",
    "step = 1\n",
    "\n",
    "past = 20\n",
    "future = 5\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "n_early=10  #10/15/20\n",
    "\n",
    "n_input_neurons=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42861119-17a1-426f-8b4f-a454837a77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Price', 'EMA1', 'EMA2', 'EMA3', 'MACD', 'SIGNAL', 'RSI', 'RSI-MA']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 251 entries, 2022-01-03 to 2022-12-30\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   EMA1    251 non-null    float64\n",
      " 1   MACD    251 non-null    float64\n",
      " 2   RSI     251 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 7.8 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA1</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>386.73</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>43.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>385.76</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>42.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>384.11</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>383.99</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>383.70</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>45.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EMA1  MACD    RSI\n",
       "Date                           \n",
       "2022-12-23  386.73 -3.11  43.83\n",
       "2022-12-27  385.76 -3.28  42.73\n",
       "2022-12-28  384.11 -3.75  39.42\n",
       "2022-12-29  383.99 -3.45  45.85\n",
       "2022-12-30  383.70 -3.26  45.09"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(f'{ab_path}',parse_dates=['Date/Time'],dayfirst=True)\n",
    "df.rename(columns={'Date/Time':date_col},inplace=True)\n",
    "df.drop(columns=['Ticker'],inplace=True)\n",
    "allCols=list(df.columns)\n",
    "print(allCols)\n",
    "\n",
    "df[date_col]=df[date_col].apply( lambda  dx :  datetime(dx.year,dx.month,dx.day ))\n",
    "df.set_index(date_col,inplace=True)\n",
    "df=df.loc[start_date:end_date,:]\n",
    "df=df[feature_cols]\n",
    "print(df.info())\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5f0480-63fa-4a04-9a56-c5999d1df02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_heatmap(data):\n",
    "#     plt.matshow(data.corr())\n",
    "#     plt.xticks(range(data.shape[1]), data.columns, fontsize=14, rotation=90)\n",
    "#     plt.gca().xaxis.tick_bottom()\n",
    "#     plt.yticks(range(data.shape[1]), data.columns, fontsize=14)\n",
    "\n",
    "#     cb = plt.colorbar()\n",
    "#     cb.ax.tick_params(labelsize=14)\n",
    "#     plt.title(\"Feature Correlation Heatmap\", fontsize=14)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# show_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b090e09-d590-4444-885f-cd6c338366a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200=0.8 x 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_split = int(split_fraction * int(df.shape[0]))\n",
    "print(f\"{train_split}={split_fraction} x {int(len(df.shape))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946cf4b7-550e-47ea-a8d0-2869e0e3c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 251 entries, 2022-01-03 to 2022-12-30\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   EMA1    251 non-null    float64\n",
      " 1   MACD    251 non-null    float64\n",
      " 2   RSI     251 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 7.8 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMA1</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>386.73</td>\n",
       "      <td>-3.11</td>\n",
       "      <td>43.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>385.76</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>42.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>384.11</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>383.99</td>\n",
       "      <td>-3.45</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>383.70</td>\n",
       "      <td>-3.26</td>\n",
       "      <td>45.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              EMA1  MACD    RSI\n",
       "Date                           \n",
       "2022-12-23  386.73 -3.11  43.83\n",
       "2022-12-27  385.76 -3.28  42.73\n",
       "2022-12-28  384.11 -3.75  39.42\n",
       "2022-12-29  383.99 -3.45  45.85\n",
       "2022-12-30  383.70 -3.26  45.09"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df.copy()\n",
    "print(features.info())\n",
    "features.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e4297f-9541-4d04-84ad-ccbb81f36d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 251 entries, 0 to 250\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       251 non-null    float64\n",
      " 1   1       251 non-null    float64\n",
      " 2   2       251 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 6.0 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-1.037575</td>\n",
       "      <td>-0.172537</td>\n",
       "      <td>-0.203613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-1.071431</td>\n",
       "      <td>-0.209333</td>\n",
       "      <td>-0.314858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-1.129019</td>\n",
       "      <td>-0.311061</td>\n",
       "      <td>-0.649603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-1.133207</td>\n",
       "      <td>-0.246128</td>\n",
       "      <td>0.000673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-1.143329</td>\n",
       "      <td>-0.205004</td>\n",
       "      <td>-0.076187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "246 -1.037575 -0.172537 -0.203613\n",
       "247 -1.071431 -0.209333 -0.314858\n",
       "248 -1.129019 -0.311061 -0.649603\n",
       "249 -1.133207 -0.246128  0.000673\n",
       "250 -1.143329 -0.205004 -0.076187"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(data, train_split):\n",
    "    data_mean = data[:train_split].mean(axis=0) # nomoalize only train data\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    return (data - data_mean) / data_std\n",
    "\n",
    "features = normalize(features.values, train_split)\n",
    "features = pd.DataFrame(features)\n",
    "print(features.info())\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c294b0cf-3c89-4ce7-966b-514a0662628d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3) (51, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = features.loc[0 : train_split - 1]\n",
    "val_data = features.loc[train_split:]\n",
    "print(train_data.shape,val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c3bc135-f71f-47c8-a8a3-3bee83d1582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=25 and end=225 and sequence_length=20\n"
     ]
    }
   ],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "sequence_length = int(past / step)\n",
    "\n",
    "print(f\"start={start} and end={end} and sequence_length={sequence_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d23f1a8e-1c91-46f0-9ef5-799c0779d2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 1)\n",
      "[[-1.09233502]\n",
      " [-1.10774872]\n",
      " [-1.12683234]\n",
      " [-1.1339887 ]\n",
      " [-1.12793332]]\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data[[i for i in range(len(feature_cols))]].values\n",
    "print(x_train.shape)\n",
    "print(x_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1ad2c3bb-9d14-4a16-b340-6f408f5521a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 1)\n",
      "           0\n",
      "70 -1.047195\n",
      "71 -1.042057\n",
      "72 -1.045910\n",
      "73 -1.042791\n",
      "74 -1.040956\n"
     ]
    }
   ],
   "source": [
    "y_train = features.iloc[start:end][[target_col_index]]\n",
    "print(y_train.shape)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "328ea062-98dd-446e-85cd-07bbceb407a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7818d839-029b-48aa-a866-cc8cb5361561",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_end = len(val_data) - past - future\n",
    "\n",
    "label_start = train_split + past + future\n",
    "\n",
    "x_val = val_data.iloc[:x_end][[i for i in range(len(feature_cols))]].values\n",
    "y_val = features.iloc[label_start:][[target_col_index]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a2f666a8-c4c4-498a-8d4a-59579c9f41ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 1)\n",
      "[[2.76916233]\n",
      " [2.77998861]\n",
      " [2.78751196]\n",
      " [2.79595279]\n",
      " [2.79760426]]\n"
     ]
    }
   ],
   "source": [
    "print(x_val.shape)\n",
    "print(x_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e7c8c35e-7187-490b-abe2-72a4f8738e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 1)\n",
      "             0\n",
      "1681  3.385894\n",
      "1682  3.387545\n",
      "1683  3.382591\n",
      "1684  3.366626\n",
      "1685  3.357268\n"
     ]
    }
   ],
   "source": [
    "print(y_val.shape)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1ba7fc6f-2536-473d-ada3-4463667e0951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (32, 60, 1)\n",
      "Target shape: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "912a142b-e45b-4fce-9767-2cb0ffb2977d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 60, 1)]           0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 120)               58560     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1210      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59,770\n",
      "Trainable params: 59,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))\n",
    "lstm_out = keras.layers.LSTM(n_input_neurons)(inputs)\n",
    "outputs = keras.layers.Dense(future)(lstm_out)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam',loss=main_loss,metrics=[main_obj_metric])\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "091b6420-16b8-4d21-b806-06c10b8a9664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.4268 - mean_absolute_error: 0.4268\n",
      "Epoch 1: val_loss improved from inf to 0.71553, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 5s 60ms/step - loss: 0.4281 - mean_absolute_error: 0.4281 - val_loss: 0.7155 - val_mean_absolute_error: 0.7155\n",
      "Epoch 2/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 1.1099 - mean_absolute_error: 1.1099\n",
      "Epoch 2: val_loss did not improve from 0.71553\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.1221 - mean_absolute_error: 1.1221 - val_loss: 2.4325 - val_mean_absolute_error: 2.4325\n",
      "Epoch 3/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.7050 - mean_absolute_error: 0.7050\n",
      "Epoch 3: val_loss did not improve from 0.71553\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.7216 - mean_absolute_error: 0.7216 - val_loss: 2.4188 - val_mean_absolute_error: 2.4188\n",
      "Epoch 4/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4239 - mean_absolute_error: 0.4239\n",
      "Epoch 4: val_loss did not improve from 0.71553\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.4239 - mean_absolute_error: 0.4239 - val_loss: 0.7421 - val_mean_absolute_error: 0.7421\n",
      "Epoch 5/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.7938 - mean_absolute_error: 0.7938\n",
      "Epoch 5: val_loss did not improve from 0.71553\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.7938 - mean_absolute_error: 0.7938 - val_loss: 1.1371 - val_mean_absolute_error: 1.1371\n",
      "Epoch 6/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.4225 - mean_absolute_error: 0.4225\n",
      "Epoch 6: val_loss did not improve from 0.71553\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.4225 - mean_absolute_error: 0.4225 - val_loss: 0.8686 - val_mean_absolute_error: 0.8686\n",
      "Epoch 7/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.2513 - mean_absolute_error: 0.2513\n",
      "Epoch 7: val_loss improved from 0.71553 to 0.46688, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.2513 - mean_absolute_error: 0.2513 - val_loss: 0.4669 - val_mean_absolute_error: 0.4669\n",
      "Epoch 8/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.2109 - mean_absolute_error: 0.2109\n",
      "Epoch 8: val_loss improved from 0.46688 to 0.39140, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.2125 - mean_absolute_error: 0.2125 - val_loss: 0.3914 - val_mean_absolute_error: 0.3914\n",
      "Epoch 9/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.2104 - mean_absolute_error: 0.2104\n",
      "Epoch 9: val_loss improved from 0.39140 to 0.36125, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.2104 - mean_absolute_error: 0.2104 - val_loss: 0.3612 - val_mean_absolute_error: 0.3612\n",
      "Epoch 10/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1417 - mean_absolute_error: 0.1417\n",
      "Epoch 10: val_loss improved from 0.36125 to 0.29998, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 3s 54ms/step - loss: 0.1417 - mean_absolute_error: 0.1417 - val_loss: 0.3000 - val_mean_absolute_error: 0.3000\n",
      "Epoch 11/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.1854 - mean_absolute_error: 0.1854\n",
      "Epoch 11: val_loss improved from 0.29998 to 0.29024, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.1844 - mean_absolute_error: 0.1844 - val_loss: 0.2902 - val_mean_absolute_error: 0.2902\n",
      "Epoch 12/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1163 - mean_absolute_error: 0.1163\n",
      "Epoch 12: val_loss did not improve from 0.29024\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1163 - mean_absolute_error: 0.1163 - val_loss: 0.3012 - val_mean_absolute_error: 0.3012\n",
      "Epoch 13/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.1167 - mean_absolute_error: 0.1167\n",
      "Epoch 13: val_loss improved from 0.29024 to 0.27356, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1175 - mean_absolute_error: 0.1175 - val_loss: 0.2736 - val_mean_absolute_error: 0.2736\n",
      "Epoch 14/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1566 - mean_absolute_error: 0.1566\n",
      "Epoch 14: val_loss improved from 0.27356 to 0.27301, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.1566 - mean_absolute_error: 0.1566 - val_loss: 0.2730 - val_mean_absolute_error: 0.2730\n",
      "Epoch 15/150\n",
      "48/49 [============================>.] - ETA: 0s - loss: 0.1003 - mean_absolute_error: 0.1003\n",
      "Epoch 15: val_loss improved from 0.27301 to 0.27001, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.1000 - mean_absolute_error: 0.1000 - val_loss: 0.2700 - val_mean_absolute_error: 0.2700\n",
      "Epoch 16/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1274 - mean_absolute_error: 0.1274\n",
      "Epoch 16: val_loss improved from 0.27001 to 0.25694, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1274 - mean_absolute_error: 0.1274 - val_loss: 0.2569 - val_mean_absolute_error: 0.2569\n",
      "Epoch 17/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1052 - mean_absolute_error: 0.1052\n",
      "Epoch 17: val_loss did not improve from 0.25694\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1052 - mean_absolute_error: 0.1052 - val_loss: 0.2607 - val_mean_absolute_error: 0.2607\n",
      "Epoch 18/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1025 - mean_absolute_error: 0.1025\n",
      "Epoch 18: val_loss did not improve from 0.25694\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1025 - mean_absolute_error: 0.1025 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
      "Epoch 19/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1070 - mean_absolute_error: 0.1070\n",
      "Epoch 19: val_loss did not improve from 0.25694\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1070 - mean_absolute_error: 0.1070 - val_loss: 0.2574 - val_mean_absolute_error: 0.2574\n",
      "Epoch 20/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1130 - mean_absolute_error: 0.1130\n",
      "Epoch 20: val_loss did not improve from 0.25694\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1130 - mean_absolute_error: 0.1130 - val_loss: 0.2575 - val_mean_absolute_error: 0.2575\n",
      "Epoch 21/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1176 - mean_absolute_error: 0.1176\n",
      "Epoch 21: val_loss improved from 0.25694 to 0.25625, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1176 - mean_absolute_error: 0.1176 - val_loss: 0.2563 - val_mean_absolute_error: 0.2563\n",
      "Epoch 22/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1094 - mean_absolute_error: 0.1094\n",
      "Epoch 22: val_loss did not improve from 0.25625\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1094 - mean_absolute_error: 0.1094 - val_loss: 0.2589 - val_mean_absolute_error: 0.2589\n",
      "Epoch 23/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1067 - mean_absolute_error: 0.1067\n",
      "Epoch 23: val_loss improved from 0.25625 to 0.25265, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1067 - mean_absolute_error: 0.1067 - val_loss: 0.2527 - val_mean_absolute_error: 0.2527\n",
      "Epoch 24/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1064 - mean_absolute_error: 0.1064\n",
      "Epoch 24: val_loss improved from 0.25265 to 0.24971, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1064 - mean_absolute_error: 0.1064 - val_loss: 0.2497 - val_mean_absolute_error: 0.2497\n",
      "Epoch 25/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1020 - mean_absolute_error: 0.1020\n",
      "Epoch 25: val_loss improved from 0.24971 to 0.24895, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1020 - mean_absolute_error: 0.1020 - val_loss: 0.2490 - val_mean_absolute_error: 0.2490\n",
      "Epoch 26/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0971 - mean_absolute_error: 0.0971\n",
      "Epoch 26: val_loss did not improve from 0.24895\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0971 - mean_absolute_error: 0.0971 - val_loss: 0.2498 - val_mean_absolute_error: 0.2498\n",
      "Epoch 27/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0993 - mean_absolute_error: 0.0993\n",
      "Epoch 27: val_loss improved from 0.24895 to 0.24642, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0993 - mean_absolute_error: 0.0993 - val_loss: 0.2464 - val_mean_absolute_error: 0.2464\n",
      "Epoch 28/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1024 - mean_absolute_error: 0.1024\n",
      "Epoch 28: val_loss improved from 0.24642 to 0.24547, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1024 - mean_absolute_error: 0.1024 - val_loss: 0.2455 - val_mean_absolute_error: 0.2455\n",
      "Epoch 29/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1035 - mean_absolute_error: 0.1035\n",
      "Epoch 29: val_loss improved from 0.24547 to 0.24414, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1035 - mean_absolute_error: 0.1035 - val_loss: 0.2441 - val_mean_absolute_error: 0.2441\n",
      "Epoch 30/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1029 - mean_absolute_error: 0.1029\n",
      "Epoch 30: val_loss improved from 0.24414 to 0.24202, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.1029 - mean_absolute_error: 0.1029 - val_loss: 0.2420 - val_mean_absolute_error: 0.2420\n",
      "Epoch 31/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1015 - mean_absolute_error: 0.1015\n",
      "Epoch 31: val_loss did not improve from 0.24202\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.1015 - mean_absolute_error: 0.1015 - val_loss: 0.2422 - val_mean_absolute_error: 0.2422\n",
      "Epoch 32/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0993 - mean_absolute_error: 0.0993\n",
      "Epoch 32: val_loss improved from 0.24202 to 0.24055, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0993 - mean_absolute_error: 0.0993 - val_loss: 0.2405 - val_mean_absolute_error: 0.2405\n",
      "Epoch 33/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0976 - mean_absolute_error: 0.0976\n",
      "Epoch 33: val_loss improved from 0.24055 to 0.23956, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0976 - mean_absolute_error: 0.0976 - val_loss: 0.2396 - val_mean_absolute_error: 0.2396\n",
      "Epoch 34/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0974 - mean_absolute_error: 0.0974\n",
      "Epoch 34: val_loss improved from 0.23956 to 0.23861, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0974 - mean_absolute_error: 0.0974 - val_loss: 0.2386 - val_mean_absolute_error: 0.2386\n",
      "Epoch 35/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0967 - mean_absolute_error: 0.0967\n",
      "Epoch 35: val_loss did not improve from 0.23861\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0967 - mean_absolute_error: 0.0967 - val_loss: 0.2394 - val_mean_absolute_error: 0.2394\n",
      "Epoch 36/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0966 - mean_absolute_error: 0.0966\n",
      "Epoch 36: val_loss improved from 0.23861 to 0.23835, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0966 - mean_absolute_error: 0.0966 - val_loss: 0.2384 - val_mean_absolute_error: 0.2384\n",
      "Epoch 37/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0982 - mean_absolute_error: 0.0982\n",
      "Epoch 37: val_loss improved from 0.23835 to 0.23762, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0982 - mean_absolute_error: 0.0982 - val_loss: 0.2376 - val_mean_absolute_error: 0.2376\n",
      "Epoch 38/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0984 - mean_absolute_error: 0.0984\n",
      "Epoch 38: val_loss did not improve from 0.23762\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0984 - mean_absolute_error: 0.0984 - val_loss: 0.2377 - val_mean_absolute_error: 0.2377\n",
      "Epoch 39/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0978 - mean_absolute_error: 0.0978\n",
      "Epoch 39: val_loss improved from 0.23762 to 0.23699, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0978 - mean_absolute_error: 0.0978 - val_loss: 0.2370 - val_mean_absolute_error: 0.2370\n",
      "Epoch 40/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0975 - mean_absolute_error: 0.0975\n",
      "Epoch 40: val_loss improved from 0.23699 to 0.23649, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.0975 - mean_absolute_error: 0.0975 - val_loss: 0.2365 - val_mean_absolute_error: 0.2365\n",
      "Epoch 41/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0969 - mean_absolute_error: 0.0969\n",
      "Epoch 41: val_loss improved from 0.23649 to 0.23617, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0969 - mean_absolute_error: 0.0969 - val_loss: 0.2362 - val_mean_absolute_error: 0.2362\n",
      "Epoch 42/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0961 - mean_absolute_error: 0.0961\n",
      "Epoch 42: val_loss did not improve from 0.23617\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0961 - mean_absolute_error: 0.0961 - val_loss: 0.2366 - val_mean_absolute_error: 0.2366\n",
      "Epoch 43/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0959 - mean_absolute_error: 0.0959\n",
      "Epoch 43: val_loss did not improve from 0.23617\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0959 - mean_absolute_error: 0.0959 - val_loss: 0.2368 - val_mean_absolute_error: 0.2368\n",
      "Epoch 44/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0962 - mean_absolute_error: 0.0962\n",
      "Epoch 44: val_loss improved from 0.23617 to 0.23589, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0962 - mean_absolute_error: 0.0962 - val_loss: 0.2359 - val_mean_absolute_error: 0.2359\n",
      "Epoch 45/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0966 - mean_absolute_error: 0.0966\n",
      "Epoch 45: val_loss improved from 0.23589 to 0.23533, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0966 - mean_absolute_error: 0.0966 - val_loss: 0.2353 - val_mean_absolute_error: 0.2353\n",
      "Epoch 46/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.0965\n",
      "Epoch 46: val_loss improved from 0.23533 to 0.23416, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.2342 - val_mean_absolute_error: 0.2342\n",
      "Epoch 47/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0967 - mean_absolute_error: 0.0967\n",
      "Epoch 47: val_loss improved from 0.23416 to 0.23391, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0967 - mean_absolute_error: 0.0967 - val_loss: 0.2339 - val_mean_absolute_error: 0.2339\n",
      "Epoch 48/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0953 - mean_absolute_error: 0.0953\n",
      "Epoch 48: val_loss did not improve from 0.23391\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0953 - mean_absolute_error: 0.0953 - val_loss: 0.2351 - val_mean_absolute_error: 0.2351\n",
      "Epoch 49/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0948 - mean_absolute_error: 0.0948\n",
      "Epoch 49: val_loss did not improve from 0.23391\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0948 - mean_absolute_error: 0.0948 - val_loss: 0.2354 - val_mean_absolute_error: 0.2354\n",
      "Epoch 50/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0955 - mean_absolute_error: 0.0955\n",
      "Epoch 50: val_loss did not improve from 0.23391\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0955 - mean_absolute_error: 0.0955 - val_loss: 0.2345 - val_mean_absolute_error: 0.2345\n",
      "Epoch 51/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0965 - mean_absolute_error: 0.0965\n",
      "Epoch 51: val_loss improved from 0.23391 to 0.23267, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0965 - mean_absolute_error: 0.0965 - val_loss: 0.2327 - val_mean_absolute_error: 0.2327\n",
      "Epoch 52/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0969 - mean_absolute_error: 0.0969\n",
      "Epoch 52: val_loss improved from 0.23267 to 0.23172, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0969 - mean_absolute_error: 0.0969 - val_loss: 0.2317 - val_mean_absolute_error: 0.2317\n",
      "Epoch 53/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0954 - mean_absolute_error: 0.0954\n",
      "Epoch 53: val_loss improved from 0.23172 to 0.23147, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0954 - mean_absolute_error: 0.0954 - val_loss: 0.2315 - val_mean_absolute_error: 0.2315\n",
      "Epoch 54/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 54: val_loss did not improve from 0.23147\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.2319 - val_mean_absolute_error: 0.2319\n",
      "Epoch 55/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0933 - mean_absolute_error: 0.0933\n",
      "Epoch 55: val_loss did not improve from 0.23147\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0933 - mean_absolute_error: 0.0933 - val_loss: 0.2326 - val_mean_absolute_error: 0.2326\n",
      "Epoch 56/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0941 - mean_absolute_error: 0.0941\n",
      "Epoch 56: val_loss did not improve from 0.23147\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0941 - mean_absolute_error: 0.0941 - val_loss: 0.2325 - val_mean_absolute_error: 0.2325\n",
      "Epoch 57/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0954 - mean_absolute_error: 0.0954\n",
      "Epoch 57: val_loss improved from 0.23147 to 0.22955, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0954 - mean_absolute_error: 0.0954 - val_loss: 0.2295 - val_mean_absolute_error: 0.2295\n",
      "Epoch 58/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0970 - mean_absolute_error: 0.0970\n",
      "Epoch 58: val_loss improved from 0.22955 to 0.22832, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0970 - mean_absolute_error: 0.0970 - val_loss: 0.2283 - val_mean_absolute_error: 0.2283\n",
      "Epoch 59/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0950 - mean_absolute_error: 0.0950\n",
      "Epoch 59: val_loss did not improve from 0.22832\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.0950 - mean_absolute_error: 0.0950 - val_loss: 0.2298 - val_mean_absolute_error: 0.2298\n",
      "Epoch 60/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0928 - mean_absolute_error: 0.0928\n",
      "Epoch 60: val_loss did not improve from 0.22832\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0928 - mean_absolute_error: 0.0928 - val_loss: 0.2291 - val_mean_absolute_error: 0.2291\n",
      "Epoch 61/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 61: val_loss did not improve from 0.22832\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.2285 - val_mean_absolute_error: 0.2285\n",
      "Epoch 62/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0948 - mean_absolute_error: 0.0948\n",
      "Epoch 62: val_loss did not improve from 0.22832\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0948 - mean_absolute_error: 0.0948 - val_loss: 0.2286 - val_mean_absolute_error: 0.2286\n",
      "Epoch 63/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0945 - mean_absolute_error: 0.0945\n",
      "Epoch 63: val_loss did not improve from 0.22832\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0945 - mean_absolute_error: 0.0945 - val_loss: 0.2283 - val_mean_absolute_error: 0.2283\n",
      "Epoch 64/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 64: val_loss improved from 0.22832 to 0.22592, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.2259 - val_mean_absolute_error: 0.2259\n",
      "Epoch 65/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0938 - mean_absolute_error: 0.0938\n",
      "Epoch 65: val_loss improved from 0.22592 to 0.22402, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.2240 - val_mean_absolute_error: 0.2240\n",
      "Epoch 66/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0951 - mean_absolute_error: 0.0951\n",
      "Epoch 66: val_loss did not improve from 0.22402\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.2264 - val_mean_absolute_error: 0.2264\n",
      "Epoch 67/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0917 - mean_absolute_error: 0.0917\n",
      "Epoch 67: val_loss did not improve from 0.22402\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0917 - mean_absolute_error: 0.0917 - val_loss: 0.2291 - val_mean_absolute_error: 0.2291\n",
      "Epoch 68/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0905 - mean_absolute_error: 0.0905\n",
      "Epoch 68: val_loss did not improve from 0.22402\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0905 - mean_absolute_error: 0.0905 - val_loss: 0.2251 - val_mean_absolute_error: 0.2251\n",
      "Epoch 69/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0938 - mean_absolute_error: 0.0938\n",
      "Epoch 69: val_loss improved from 0.22402 to 0.22239, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.2224 - val_mean_absolute_error: 0.2224\n",
      "Epoch 70/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0956 - mean_absolute_error: 0.0956\n",
      "Epoch 70: val_loss did not improve from 0.22239\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0956 - mean_absolute_error: 0.0956 - val_loss: 0.2251 - val_mean_absolute_error: 0.2251\n",
      "Epoch 71/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.0931\n",
      "Epoch 71: val_loss did not improve from 0.22239\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0931 - mean_absolute_error: 0.0931 - val_loss: 0.2229 - val_mean_absolute_error: 0.2229\n",
      "Epoch 72/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0910 - mean_absolute_error: 0.0910\n",
      "Epoch 72: val_loss did not improve from 0.22239\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0910 - mean_absolute_error: 0.0910 - val_loss: 0.2228 - val_mean_absolute_error: 0.2228\n",
      "Epoch 73/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 73: val_loss did not improve from 0.22239\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.2227 - val_mean_absolute_error: 0.2227\n",
      "Epoch 74/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0923 - mean_absolute_error: 0.0923\n",
      "Epoch 74: val_loss did not improve from 0.22239\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0923 - mean_absolute_error: 0.0923 - val_loss: 0.2235 - val_mean_absolute_error: 0.2235\n",
      "Epoch 75/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0923 - mean_absolute_error: 0.0923\n",
      "Epoch 75: val_loss did not improve from 0.22239\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0923 - mean_absolute_error: 0.0923 - val_loss: 0.2235 - val_mean_absolute_error: 0.2235\n",
      "Epoch 76/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0944 - mean_absolute_error: 0.0944\n",
      "Epoch 76: val_loss improved from 0.22239 to 0.21953, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.2195 - val_mean_absolute_error: 0.2195\n",
      "Epoch 77/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0944 - mean_absolute_error: 0.0944\n",
      "Epoch 77: val_loss did not improve from 0.21953\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.2213 - val_mean_absolute_error: 0.2213\n",
      "Epoch 78/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 78: val_loss did not improve from 0.21953\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.2216 - val_mean_absolute_error: 0.2216\n",
      "Epoch 79/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0897 - mean_absolute_error: 0.0897\n",
      "Epoch 79: val_loss did not improve from 0.21953\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0897 - mean_absolute_error: 0.0897 - val_loss: 0.2248 - val_mean_absolute_error: 0.2248\n",
      "Epoch 80/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 80: val_loss improved from 0.21953 to 0.21890, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.2189 - val_mean_absolute_error: 0.2189\n",
      "Epoch 81/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0914 - mean_absolute_error: 0.0914\n",
      "Epoch 81: val_loss improved from 0.21890 to 0.21880, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0914 - mean_absolute_error: 0.0914 - val_loss: 0.2188 - val_mean_absolute_error: 0.2188\n",
      "Epoch 82/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0909 - mean_absolute_error: 0.0909\n",
      "Epoch 82: val_loss did not improve from 0.21880\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0909 - mean_absolute_error: 0.0909 - val_loss: 0.2244 - val_mean_absolute_error: 0.2244\n",
      "Epoch 83/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 83: val_loss did not improve from 0.21880\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.2218 - val_mean_absolute_error: 0.2218\n",
      "Epoch 84/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0914 - mean_absolute_error: 0.0914\n",
      "Epoch 84: val_loss improved from 0.21880 to 0.21824, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0914 - mean_absolute_error: 0.0914 - val_loss: 0.2182 - val_mean_absolute_error: 0.2182\n",
      "Epoch 85/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0969 - mean_absolute_error: 0.0969\n",
      "Epoch 85: val_loss did not improve from 0.21824\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0969 - mean_absolute_error: 0.0969 - val_loss: 0.2191 - val_mean_absolute_error: 0.2191\n",
      "Epoch 86/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0924 - mean_absolute_error: 0.0924\n",
      "Epoch 86: val_loss did not improve from 0.21824\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.2215 - val_mean_absolute_error: 0.2215\n",
      "Epoch 87/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0889 - mean_absolute_error: 0.0889\n",
      "Epoch 87: val_loss did not improve from 0.21824\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0889 - mean_absolute_error: 0.0889 - val_loss: 0.2273 - val_mean_absolute_error: 0.2273\n",
      "Epoch 88/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0880 - mean_absolute_error: 0.0880\n",
      "Epoch 88: val_loss did not improve from 0.21824\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0880 - mean_absolute_error: 0.0880 - val_loss: 0.2190 - val_mean_absolute_error: 0.2190\n",
      "Epoch 89/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0924 - mean_absolute_error: 0.0924\n",
      "Epoch 89: val_loss improved from 0.21824 to 0.21643, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.2164 - val_mean_absolute_error: 0.2164\n",
      "Epoch 90/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0936 - mean_absolute_error: 0.0936\n",
      "Epoch 90: val_loss did not improve from 0.21643\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0936 - mean_absolute_error: 0.0936 - val_loss: 0.2184 - val_mean_absolute_error: 0.2184\n",
      "Epoch 91/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0930 - mean_absolute_error: 0.0930\n",
      "Epoch 91: val_loss did not improve from 0.21643\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.2214 - val_mean_absolute_error: 0.2214\n",
      "Epoch 92/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0874 - mean_absolute_error: 0.0874\n",
      "Epoch 92: val_loss did not improve from 0.21643\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0874 - mean_absolute_error: 0.0874 - val_loss: 0.2223 - val_mean_absolute_error: 0.2223\n",
      "Epoch 93/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0924 - mean_absolute_error: 0.0924\n",
      "Epoch 93: val_loss did not improve from 0.21643\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0924 - mean_absolute_error: 0.0924 - val_loss: 0.2172 - val_mean_absolute_error: 0.2172\n",
      "Epoch 94/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0899 - mean_absolute_error: 0.0899\n",
      "Epoch 94: val_loss improved from 0.21643 to 0.21454, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 3s 54ms/step - loss: 0.0899 - mean_absolute_error: 0.0899 - val_loss: 0.2145 - val_mean_absolute_error: 0.2145\n",
      "Epoch 95/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0957 - mean_absolute_error: 0.0957\n",
      "Epoch 95: val_loss did not improve from 0.21454\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0957 - mean_absolute_error: 0.0957 - val_loss: 0.2162 - val_mean_absolute_error: 0.2162\n",
      "Epoch 96/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0885 - mean_absolute_error: 0.0885\n",
      "Epoch 96: val_loss did not improve from 0.21454\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0885 - mean_absolute_error: 0.0885 - val_loss: 0.2176 - val_mean_absolute_error: 0.2176\n",
      "Epoch 97/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0914 - mean_absolute_error: 0.0914\n",
      "Epoch 97: val_loss did not improve from 0.21454\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0914 - mean_absolute_error: 0.0914 - val_loss: 0.2230 - val_mean_absolute_error: 0.2230\n",
      "Epoch 98/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0870 - mean_absolute_error: 0.0870\n",
      "Epoch 98: val_loss did not improve from 0.21454\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0870 - mean_absolute_error: 0.0870 - val_loss: 0.2168 - val_mean_absolute_error: 0.2168\n",
      "Epoch 99/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0935 - mean_absolute_error: 0.0935\n",
      "Epoch 99: val_loss did not improve from 0.21454\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0935 - mean_absolute_error: 0.0935 - val_loss: 0.2149 - val_mean_absolute_error: 0.2149\n",
      "Epoch 100/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0894 - mean_absolute_error: 0.0894\n",
      "Epoch 100: val_loss improved from 0.21454 to 0.21442, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0894 - mean_absolute_error: 0.0894 - val_loss: 0.2144 - val_mean_absolute_error: 0.2144\n",
      "Epoch 101/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0921 - mean_absolute_error: 0.0921\n",
      "Epoch 101: val_loss did not improve from 0.21442\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0921 - mean_absolute_error: 0.0921 - val_loss: 0.2167 - val_mean_absolute_error: 0.2167\n",
      "Epoch 102/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0845 - mean_absolute_error: 0.0845\n",
      "Epoch 102: val_loss did not improve from 0.21442\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.2162 - val_mean_absolute_error: 0.2162\n",
      "Epoch 103/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0898 - mean_absolute_error: 0.0898\n",
      "Epoch 103: val_loss did not improve from 0.21442\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0898 - mean_absolute_error: 0.0898 - val_loss: 0.2209 - val_mean_absolute_error: 0.2209\n",
      "Epoch 104/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0855 - mean_absolute_error: 0.0855\n",
      "Epoch 104: val_loss did not improve from 0.21442\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0855 - mean_absolute_error: 0.0855 - val_loss: 0.2157 - val_mean_absolute_error: 0.2157\n",
      "Epoch 105/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0930 - mean_absolute_error: 0.0930\n",
      "Epoch 105: val_loss did not improve from 0.21442\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.2146 - val_mean_absolute_error: 0.2146\n",
      "Epoch 106/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0890 - mean_absolute_error: 0.0890\n",
      "Epoch 106: val_loss improved from 0.21442 to 0.21422, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0890 - mean_absolute_error: 0.0890 - val_loss: 0.2142 - val_mean_absolute_error: 0.2142\n",
      "Epoch 107/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0920 - mean_absolute_error: 0.0920\n",
      "Epoch 107: val_loss did not improve from 0.21422\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.0920 - mean_absolute_error: 0.0920 - val_loss: 0.2197 - val_mean_absolute_error: 0.2197\n",
      "Epoch 108/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0826 - mean_absolute_error: 0.0826\n",
      "Epoch 108: val_loss did not improve from 0.21422\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.2196 - val_mean_absolute_error: 0.2196\n",
      "Epoch 109/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0940 - mean_absolute_error: 0.0940\n",
      "Epoch 109: val_loss did not improve from 0.21422\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0940 - mean_absolute_error: 0.0940 - val_loss: 0.2250 - val_mean_absolute_error: 0.2250\n",
      "Epoch 110/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0822 - mean_absolute_error: 0.0822\n",
      "Epoch 110: val_loss did not improve from 0.21422\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0822 - mean_absolute_error: 0.0822 - val_loss: 0.2199 - val_mean_absolute_error: 0.2199\n",
      "Epoch 111/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 111: val_loss did not improve from 0.21422\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.2152 - val_mean_absolute_error: 0.2152\n",
      "Epoch 112/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0886 - mean_absolute_error: 0.0886\n",
      "Epoch 112: val_loss improved from 0.21422 to 0.21165, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0886 - mean_absolute_error: 0.0886 - val_loss: 0.2117 - val_mean_absolute_error: 0.2117\n",
      "Epoch 113/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0969 - mean_absolute_error: 0.0969\n",
      "Epoch 113: val_loss did not improve from 0.21165\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0969 - mean_absolute_error: 0.0969 - val_loss: 0.2169 - val_mean_absolute_error: 0.2169\n",
      "Epoch 114/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0860 - mean_absolute_error: 0.0860\n",
      "Epoch 114: val_loss did not improve from 0.21165\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0860 - mean_absolute_error: 0.0860 - val_loss: 0.2123 - val_mean_absolute_error: 0.2123\n",
      "Epoch 115/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0954 - mean_absolute_error: 0.0954\n",
      "Epoch 115: val_loss did not improve from 0.21165\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0954 - mean_absolute_error: 0.0954 - val_loss: 0.2142 - val_mean_absolute_error: 0.2142\n",
      "Epoch 116/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0840 - mean_absolute_error: 0.0840\n",
      "Epoch 116: val_loss improved from 0.21165 to 0.21154, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0840 - mean_absolute_error: 0.0840 - val_loss: 0.2115 - val_mean_absolute_error: 0.2115\n",
      "Epoch 117/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0914 - mean_absolute_error: 0.0914\n",
      "Epoch 117: val_loss did not improve from 0.21154\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0914 - mean_absolute_error: 0.0914 - val_loss: 0.2148 - val_mean_absolute_error: 0.2148\n",
      "Epoch 118/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0835 - mean_absolute_error: 0.0835\n",
      "Epoch 118: val_loss improved from 0.21154 to 0.20942, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0835 - mean_absolute_error: 0.0835 - val_loss: 0.2094 - val_mean_absolute_error: 0.2094\n",
      "Epoch 119/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0887 - mean_absolute_error: 0.0887\n",
      "Epoch 119: val_loss did not improve from 0.20942\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0887 - mean_absolute_error: 0.0887 - val_loss: 0.2102 - val_mean_absolute_error: 0.2102\n",
      "Epoch 120/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0958 - mean_absolute_error: 0.0958\n",
      "Epoch 120: val_loss did not improve from 0.20942\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0958 - mean_absolute_error: 0.0958 - val_loss: 0.2139 - val_mean_absolute_error: 0.2139\n",
      "Epoch 121/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0886 - mean_absolute_error: 0.0886\n",
      "Epoch 121: val_loss did not improve from 0.20942\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0886 - mean_absolute_error: 0.0886 - val_loss: 0.2154 - val_mean_absolute_error: 0.2154\n",
      "Epoch 122/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0916 - mean_absolute_error: 0.0916\n",
      "Epoch 122: val_loss did not improve from 0.20942\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.2216 - val_mean_absolute_error: 0.2216\n",
      "Epoch 123/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0859 - mean_absolute_error: 0.0859\n",
      "Epoch 123: val_loss improved from 0.20942 to 0.20784, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0859 - mean_absolute_error: 0.0859 - val_loss: 0.2078 - val_mean_absolute_error: 0.2078\n",
      "Epoch 124/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0923 - mean_absolute_error: 0.0923\n",
      "Epoch 124: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0923 - mean_absolute_error: 0.0923 - val_loss: 0.2142 - val_mean_absolute_error: 0.2142\n",
      "Epoch 125/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0855 - mean_absolute_error: 0.0855\n",
      "Epoch 125: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0855 - mean_absolute_error: 0.0855 - val_loss: 0.2110 - val_mean_absolute_error: 0.2110\n",
      "Epoch 126/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0857 - mean_absolute_error: 0.0857\n",
      "Epoch 126: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0857 - mean_absolute_error: 0.0857 - val_loss: 0.2167 - val_mean_absolute_error: 0.2167\n",
      "Epoch 127/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0813 - mean_absolute_error: 0.0813\n",
      "Epoch 127: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0813 - mean_absolute_error: 0.0813 - val_loss: 0.2147 - val_mean_absolute_error: 0.2147\n",
      "Epoch 128/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0845 - mean_absolute_error: 0.0845\n",
      "Epoch 128: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0845 - mean_absolute_error: 0.0845 - val_loss: 0.2114 - val_mean_absolute_error: 0.2114\n",
      "Epoch 129/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0860 - mean_absolute_error: 0.0860\n",
      "Epoch 129: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0860 - mean_absolute_error: 0.0860 - val_loss: 0.2103 - val_mean_absolute_error: 0.2103\n",
      "Epoch 130/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0879 - mean_absolute_error: 0.0879\n",
      "Epoch 130: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0879 - mean_absolute_error: 0.0879 - val_loss: 0.2162 - val_mean_absolute_error: 0.2162\n",
      "Epoch 131/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0796 - mean_absolute_error: 0.0796\n",
      "Epoch 131: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0796 - mean_absolute_error: 0.0796 - val_loss: 0.2227 - val_mean_absolute_error: 0.2227\n",
      "Epoch 132/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0895 - mean_absolute_error: 0.0895\n",
      "Epoch 132: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0895 - mean_absolute_error: 0.0895 - val_loss: 0.2133 - val_mean_absolute_error: 0.2133\n",
      "Epoch 133/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0826 - mean_absolute_error: 0.0826\n",
      "Epoch 133: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0826 - mean_absolute_error: 0.0826 - val_loss: 0.2200 - val_mean_absolute_error: 0.2200\n",
      "Epoch 134/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0983 - mean_absolute_error: 0.0983\n",
      "Epoch 134: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0983 - mean_absolute_error: 0.0983 - val_loss: 0.2132 - val_mean_absolute_error: 0.2132\n",
      "Epoch 135/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0847 - mean_absolute_error: 0.0847\n",
      "Epoch 135: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0847 - mean_absolute_error: 0.0847 - val_loss: 0.2138 - val_mean_absolute_error: 0.2138\n",
      "Epoch 136/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.1021 - mean_absolute_error: 0.1021\n",
      "Epoch 136: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.1021 - mean_absolute_error: 0.1021 - val_loss: 0.2181 - val_mean_absolute_error: 0.2181\n",
      "Epoch 137/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0805 - mean_absolute_error: 0.0805\n",
      "Epoch 137: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0805 - mean_absolute_error: 0.0805 - val_loss: 0.2205 - val_mean_absolute_error: 0.2205\n",
      "Epoch 138/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0919 - mean_absolute_error: 0.0919\n",
      "Epoch 138: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.2085 - val_mean_absolute_error: 0.2085\n",
      "Epoch 139/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0843 - mean_absolute_error: 0.0843\n",
      "Epoch 139: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.2181 - val_mean_absolute_error: 0.2181\n",
      "Epoch 140/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0929 - mean_absolute_error: 0.0929\n",
      "Epoch 140: val_loss did not improve from 0.20784\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0929 - mean_absolute_error: 0.0929 - val_loss: 0.2209 - val_mean_absolute_error: 0.2209\n",
      "Epoch 141/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0813 - mean_absolute_error: 0.0813\n",
      "Epoch 141: val_loss improved from 0.20784 to 0.20625, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.0813 - mean_absolute_error: 0.0813 - val_loss: 0.2063 - val_mean_absolute_error: 0.2063\n",
      "Epoch 142/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 142: val_loss improved from 0.20625 to 0.20593, saving model to model_SP500_checkpoint.h5\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.2059 - val_mean_absolute_error: 0.2059\n",
      "Epoch 143/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0843 - mean_absolute_error: 0.0843\n",
      "Epoch 143: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0843 - mean_absolute_error: 0.0843 - val_loss: 0.2090 - val_mean_absolute_error: 0.2090\n",
      "Epoch 144/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0829 - mean_absolute_error: 0.0829\n",
      "Epoch 144: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0829 - mean_absolute_error: 0.0829 - val_loss: 0.2146 - val_mean_absolute_error: 0.2146\n",
      "Epoch 145/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0810 - mean_absolute_error: 0.0810\n",
      "Epoch 145: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0810 - mean_absolute_error: 0.0810 - val_loss: 0.2287 - val_mean_absolute_error: 0.2287\n",
      "Epoch 146/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0853 - mean_absolute_error: 0.0853\n",
      "Epoch 146: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0853 - mean_absolute_error: 0.0853 - val_loss: 0.2221 - val_mean_absolute_error: 0.2221\n",
      "Epoch 147/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0830 - mean_absolute_error: 0.0830\n",
      "Epoch 147: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0830 - mean_absolute_error: 0.0830 - val_loss: 0.2353 - val_mean_absolute_error: 0.2353\n",
      "Epoch 148/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0891 - mean_absolute_error: 0.0891\n",
      "Epoch 148: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.0891 - mean_absolute_error: 0.0891 - val_loss: 0.2265 - val_mean_absolute_error: 0.2265\n",
      "Epoch 149/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0963 - mean_absolute_error: 0.0963\n",
      "Epoch 149: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0963 - mean_absolute_error: 0.0963 - val_loss: 0.2125 - val_mean_absolute_error: 0.2125\n",
      "Epoch 150/150\n",
      "49/49 [==============================] - ETA: 0s - loss: 0.0907 - mean_absolute_error: 0.0907\n",
      "Epoch 150: val_loss did not improve from 0.20593\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.2109 - val_mean_absolute_error: 0.2109\n"
     ]
    }
   ],
   "source": [
    "path_checkpoint = f\"model_{asset_name}_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=n_early)\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f3e840db-4985-4dd1-b52a-01634318bf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_loss(history, \"Training and Validation Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9a376178-3c93-4719-a6ca-7e3b3f90af06",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 25\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataset_val\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     24\u001b[0m     show_plot(\n\u001b[1;32m---> 25\u001b[0m         [\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy(), y[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy(), model\u001b[38;5;241m.\u001b[39mpredict(x)[\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;241m12\u001b[39m,\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingle Step Prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     )\n",
      "File \u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\dev_ml_local\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\dev_ml_local\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 1 of dimension 1 out of bounds. [Op:StridedSlice] name: strided_slice/"
     ]
    }
   ],
   "source": [
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "for x, y in dataset_val.take(5):\n",
    "    show_plot(\n",
    "        [x[0][:, 1].numpy(), y[0].numpy(), model.predict(x)[0]],\n",
    "        12,\n",
    "        \"Single Step Prediction\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2691d7-fed0-4766-b66c-1ca26844fec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
