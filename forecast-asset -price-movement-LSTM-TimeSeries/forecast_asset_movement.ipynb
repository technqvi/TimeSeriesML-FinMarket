{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a9cb56bd-3c45-4f45-a2fb-c33f5198d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime,date,timedelta,timezone\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "from google.api_core.exceptions import BadRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "70cf04c4-e1ce-4eb2-b82c-8b98bae04d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following section\n",
    "# fuction\n",
    "# json and env if/else\n",
    "# return statment\n",
    "\n",
    "# import functions_framework\n",
    "# @functions_framework.http\n",
    "# def forecast_asset_movement(request):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de071b2-41b2-40db-ab1d-7743faa0199f",
   "metadata": {},
   "source": [
    "# Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "55257eb9-7ddb-4aa6-8d11-bc42344a6ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List parameter as belows\n",
      "today=\n",
      "model_id=qqq-ema1-30t5\n",
      "input 30 rows to predict output 5\n"
     ]
    }
   ],
   "source": [
    "loadModelMode='local'   # local,gcs\n",
    "\n",
    "model_id='qqq-ema1-30t5'\n",
    "today=''\n",
    "input_sequence_length =30\n",
    "output_sequence_length =5\n",
    "\n",
    "# if request.get_json():\n",
    "#     print(\"JSON Post Date Info\") # Post Method\n",
    "#     request_json = request.get_json()\n",
    "#     today=request_json['TODAY']\n",
    "#     model_id=request_json['MODEL_ID']\n",
    "#     input_sequence_length=int(request_json['INPUT_SL'])\n",
    "#     output_sequence_length=int(request_json['OUTPUT_SL'])\n",
    "# else:\n",
    "#     print(\"Enviroment Variable Info\")\n",
    "#     today=os.environ.get('TODAY', '') \n",
    "#     #today=os.environ.get('TODAY', '2023-04-28')  \n",
    "#     model_id=os.environ.get('MODEL_ID', 'spy-ema1')  \n",
    "#     input_sequence_length=int(os.environ.get('INPUT_SL', '60') ) \n",
    "#     output_sequence_length=int(os.environ.get('OUTPUT_SL', '10'))  \n",
    "\n",
    "print(\"List parameter as belows\")\n",
    "print(f\"today={today}\")\n",
    "print(f\"model_id={model_id}\")\n",
    "print(f\"input {input_sequence_length} rows to predict output {output_sequence_length}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e81398-c118-43c5-8a1e-68cfbd0d5ea2",
   "metadata": {},
   "source": [
    "# BigQuery Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "54cabd15-5e81-4075-a4a7-9aba2ebff632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pongthorn.FinAssetForecast.fin_movement_forecast\n",
      "pongthorn.FinAssetForecast.fin_data\n",
      "pongthorn.FinAssetForecast.model_ts_metadata\n"
     ]
    }
   ],
   "source": [
    "projectId='pongthorn'\n",
    "dataset_id='FinAssetForecast'\n",
    "table_id = f\"{projectId}.{dataset_id}.fin_movement_forecast\"\n",
    "table_data_id = f\"{projectId}.{dataset_id}.fin_data\"\n",
    "table_model_id= f\"{projectId}.{dataset_id}.model_ts_metadata\"\n",
    "\n",
    "print(table_id)\n",
    "print(table_data_id)\n",
    "print(table_model_id)\n",
    "\n",
    "# json_credential_file=r'C:\\Windows\\pongthorn-5decdc5124f5.json'\n",
    "# credentials = service_account.Credentials.from_service_account_file(json_credential_file)\n",
    "# client = bigquery.Client(project=projectId,credentials=credentials )\n",
    "client = bigquery.Client(project=projectId )\n",
    "\n",
    "def load_data_bq(sql:str):\n",
    " query_result=client.query(sql)\n",
    " df=query_result.to_dataframe()\n",
    " return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a7f48-7759-48bf-8806-089595651be4",
   "metadata": {},
   "source": [
    "# Load Model MetaData Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7549f76c-4efe-49a5-b201-ba34b58e7172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT * FROM `pongthorn.FinAssetForecast.model_ts_metadata`  where model_id='qqq-ema1-30t5'\n",
      "\n",
      "model_id                                                     qqq-ema1-30t5\n",
      "asset                                                                  QQQ\n",
      "prediction                                                            EMA1\n",
      "input_sequence_length                                                   30\n",
      "output_sequence_length                                                   5\n",
      "gs_model_path               gs://demo-ts-forecast-pongthorn/model_qqq_ema1\n",
      "local_model_path                                      model/model_qqq_ema1\n",
      "model_file                         EMA1_30To5_QQQ_E200S20-Y2015-2023_ma.h5\n",
      "scaler_file                    scaler_EMA1_30To5_QQQ_E200S20-Y2015-2023.gz\n",
      "scaler_pred_file          scaler_pred_EMA1_30To5_QQQ_E200S20-Y2015-2023.gz\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sqlModelMt=f\"\"\"\n",
    "SELECT * FROM `{table_model_id}`  where model_id='{model_id}'\n",
    "\"\"\"\n",
    "print(sqlModelMt)\n",
    "dfModelMeta=load_data_bq(sqlModelMt)\n",
    "if dfModelMeta.empty==False:\n",
    "    modelMeta=dfModelMeta.iloc[0,:]\n",
    "    asset_name=modelMeta['asset']\n",
    "    prediction_name=modelMeta['prediction']\n",
    "    \n",
    "    input_sequence_length=int(modelMeta['input_sequence_length'])\n",
    "    output_sequence_length=int(modelMeta['output_sequence_length'])\n",
    "    \n",
    "    model_path=modelMeta['gs_model_path']\n",
    "    local_model_path=modelMeta['local_model_path']\n",
    "    \n",
    "    model_file=modelMeta['model_file']\n",
    "    scaler_file=modelMeta['scaler_file']\n",
    "    scalerPred_file=modelMeta['scaler_pred_file']\n",
    "    print(modelMeta)\n",
    "    \n",
    "else: \n",
    "    raise Exception(f\"Not found model id  {model_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# print(f\"{today} - {asset_name} -{prediction_name}\")\n",
    "# print(\"==================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c90459-6931-49f7-9908-aaf7e99699bc",
   "metadata": {},
   "source": [
    "# Load model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2765c501-77a0-45bd-8cec-1f404d31ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from local\n",
      "model/model_qqq_ema1/EMA1_30To5_QQQ_E200S20-Y2015-2023_ma.h5\n",
      "model/model_qqq_ema1/scaler_EMA1_30To5_QQQ_E200S20-Y2015-2023.gz\n",
      "model/model_qqq_ema1/scaler_pred_EMA1_30To5_QQQ_E200S20-Y2015-2023.gz\n"
     ]
    }
   ],
   "source": [
    "if loadModelMode=='local':\n",
    " objectPaht=local_model_path\n",
    "else:\n",
    " objectPaht=model_path  \n",
    "\n",
    "model_path=f\"{objectPaht}/{model_file}\"\n",
    "scale_input_path=f\"{objectPaht}/{scaler_file}\"\n",
    "scale_output_path=f\"{objectPaht}/{scalerPred_file}\"\n",
    "\n",
    "print(f\"load model from {loadModelMode}\")   \n",
    "print(model_path)\n",
    "print(scale_input_path)\n",
    "print(scale_output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "443426bb-6329-48d8-9c1b-f5a51c31b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and Scaler Object Summary\n",
      "Scaler Max-Min\n",
      "=====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\envs\\google_base\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if loadModelMode=='local':\n",
    "    try:\n",
    "        print(\"Model and Scaler Object Summary\")\n",
    "        x_model = load_model(model_path)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex)) \n",
    "    \n",
    "    try:\n",
    "        print(\"Scaler Max-Min\")\n",
    "        x_scaler = joblib.load(scale_input_path)\n",
    "        x_scalerPred=joblib.load(scale_output_path)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        raise Exception(str(ex))\n",
    "\n",
    "    print(\"=====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "205bf465-9f2b-417c-86aa-22a5062f4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if loadModelMode=='gcs':\n",
    " try:    \n",
    "    gcs_client = storage.Client()\n",
    "\n",
    "    with open(scaler_file, 'wb') as scaler_f, open(scalerPred_file, 'wb') as scaler_pred_f,open(model_file, 'wb') as model_f:\n",
    "        gcs_client.download_blob_to_file(scale_input_path, scaler_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(scale_output_path, scaler_pred_f\n",
    "        )\n",
    "        gcs_client.download_blob_to_file(model_path, model_f\n",
    "        )\n",
    "\n",
    "    x_scaler = joblib.load(scaler_file)\n",
    "    x_scalerPred=joblib.load(scalerPred_file)\n",
    "    x_model = load_model(model_file)\n",
    " except Exception as ex:\n",
    "    print(str(ex))\n",
    "    raise Exception(str(ex))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4cbc6a3f-8264-4b1d-9424-34a3cf16177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 90)                33120     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 90)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,575\n",
      "Trainable params: 33,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "max=[397.94] and min=[98.71] and scale=[0.00334191]\n",
      "max=[397.94] and min=[98.71] and scale=[0.00334191]\n"
     ]
    }
   ],
   "source": [
    "print(x_model.summary())\n",
    "#(max - min) / (X.max(axis=0) - X.min(axis=0))\n",
    "print(f\"max={x_scaler.data_max_} and min={x_scaler.data_min_} and scale={x_scaler.scale_}\")\n",
    "print(f\"max={x_scalerPred.data_max_} and min={x_scalerPred.data_min_} and scale={x_scalerPred.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb99063-ed8b-44a9-9bd4-6d708f755cbf",
   "metadata": {},
   "source": [
    "# Declare and Initialize TS Model Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6a33b887-b266-4ff9-b2ca-a334364eb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-10 04:14:08\n"
     ]
    }
   ],
   "source": [
    "date_col='Date'\n",
    "prediction_col=prediction_name\n",
    "feature_cols=[prediction_name]\n",
    "\n",
    "\n",
    "\n",
    "nLastData=input_sequence_length*2\n",
    "\n",
    "# dt_imported=datetime.now()\n",
    "dt_imported=datetime.now(timezone.utc)\n",
    "dtStr_imported=dt_imported.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(dtStr_imported)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ce645-c4c1-4b34-a56e-fd510aa1e66f",
   "metadata": {},
   "source": [
    "# Query Fin Data from BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b682d76-f7b1-45b2-92c1-78a5c0e7af38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    select Date as LastDate  from `pongthorn.FinAssetForecast.fin_data` where Symbol='QQQ' \n",
      "    and Date='2023-06-02'\n",
      "    \n",
      "     LastDate\n",
      "0  2023-06-02\n",
      "Forecast EMA1 movement of  QQQ at 2023-06-02\n"
     ]
    }
   ],
   "source": [
    "lastDate=None\n",
    "if today=='':\n",
    "    sqlLastDate=f\"\"\" select max(Date) as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \"\"\"\n",
    "\n",
    "else:\n",
    "    sqlLastDate=f\"\"\" \n",
    "    select Date as LastDate  from `{table_data_id}` where Symbol='{asset_name}' \n",
    "    and Date='{today}'\n",
    "    \"\"\"\n",
    "print(sqlLastDate)\n",
    "results = client.query(sqlLastDate)\n",
    "dfLastDate=results.to_dataframe()\n",
    "print(dfLastDate)\n",
    "if dfLastDate.empty:\n",
    "    print( f\"Not found price data at {today}  of {asset_name}\")\n",
    "    # return f\"Not found price data at {today}  of {asset_name}\"\n",
    "else:\n",
    "    lastDate=dfLastDate.iloc[0,0]\n",
    "    today=lastDate.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "print(f\"Forecast {prediction_col} movement of  {asset_name} at {today}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d4835aad-60d9-4c16-b69e-7da926e9ab79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get last price of QQQ\n",
      "select prediction_date,asset_name,prediction_name,pred_timestamp from `pongthorn.FinAssetForecast.fin_movement_forecast` \n",
      "where prediction_date='2023-06-02' and   asset_name='QQQ' and prediction_name='EMA1'\n",
      "order by pred_timestamp \n",
      "\n",
      "QQQ-EMA1 at 2023-06-02 has not been predicted price movement yet.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get last price of {asset_name}\")\n",
    "sqlLastPred=f\"\"\"select prediction_date,asset_name,prediction_name,pred_timestamp from `{table_id}` \n",
    "where prediction_date='{today}' and   asset_name='{asset_name}' and prediction_name='{prediction_col}'\n",
    "order by pred_timestamp \n",
    "\"\"\"\n",
    "print(sqlLastPred)\n",
    "dfLastPred=load_data_bq(sqlLastPred)\n",
    "if dfLastPred.empty==False:\n",
    "   dfLastPred=dfLastPred.drop_duplicates(subset=['prediction_date','asset_name','prediction_name'],keep='last') \n",
    "   print(f\"{asset_name}-{prediction_col}-{today} has been predicted price movement\")\n",
    "   print(dfLastPred)\n",
    "   #return \"there is one record of prediction price movement\"\n",
    "else:\n",
    "   print(f\"{asset_name}-{prediction_col} at {today} has not been predicted price movement yet.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ab61afa5-0cbd-46c9-895d-20ddcd23b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get data from 2023-04-03 - 2023-06-02 as input to forecast\n"
     ]
    }
   ],
   "source": [
    "dayAgo=datetime.strptime(today,'%Y-%m-%d') +timedelta(days=-nLastData)\n",
    "print(f\"Get data from {dayAgo.strftime('%Y-%m-%d')} - {today} as input to forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "729b0f1f-020a-4c61-a80a-0403c6ecd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT  *  FROM `pongthorn.FinAssetForecast.fin_data`  \n",
      "Where  Date between  DATE_SUB(DATE '2023-06-02', INTERVAL 60 DAY) \n",
      "and '2023-06-02' and Symbol='QQQ' order by Date,ImportDateTime\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 43 entries, 2023-04-03 to 2023-06-02\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Symbol          43 non-null     object        \n",
      " 1   Close           43 non-null     float64       \n",
      " 2   EMA1            43 non-null     float64       \n",
      " 3   EMA2            43 non-null     float64       \n",
      " 4   MACD            43 non-null     float64       \n",
      " 5   SIGNAL          43 non-null     float64       \n",
      " 6   ImportDateTime  43 non-null     datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(1)\n",
      "memory usage: 2.7+ KB\n",
      "None\n",
      "           Symbol   Close             ImportDateTime\n",
      "Date                                                \n",
      "2023-04-03    QQQ  320.15 2023-06-09 14:30:20.942119\n",
      "2023-04-04    QQQ  319.07 2023-06-09 14:30:20.942119\n",
      "2023-04-05    QQQ  315.92 2023-06-09 14:30:20.942119\n",
      "2023-04-06    QQQ  318.05 2023-06-09 14:30:20.942119\n",
      "2023-04-10    QQQ  317.87 2023-06-09 14:30:20.942119\n",
      "           Symbol   Close             ImportDateTime\n",
      "Date                                                \n",
      "2023-05-26    QQQ  348.40 2023-06-09 14:30:20.942119\n",
      "2023-05-30    QQQ  349.98 2023-06-09 14:30:20.942119\n",
      "2023-05-31    QQQ  347.99 2023-06-09 14:30:20.942119\n",
      "2023-06-01    QQQ  352.01 2023-06-09 14:30:20.942119\n",
      "2023-06-02    QQQ  354.65 2023-06-09 14:30:20.942119\n"
     ]
    }
   ],
   "source": [
    "sql=f\"\"\"\n",
    "SELECT  *  FROM `{table_data_id}`  \n",
    "Where  {date_col} between  DATE_SUB(DATE '{today}', INTERVAL {nLastData} DAY) \n",
    "and '{today}' and Symbol='{asset_name}' order by {date_col},ImportDateTime\n",
    "\"\"\"\n",
    "print(sql)\n",
    "query_result=client.query(sql)\n",
    "df=query_result.to_dataframe()\n",
    "\n",
    "df=df.drop_duplicates(subset=[date_col,'Symbol'],keep='last')\n",
    "df[date_col]=pd.to_datetime(df[date_col],format='%Y-%m-%d')\n",
    "df.set_index(date_col,inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].head())\n",
    "print(df[['Symbol','Close' ,'ImportDateTime']].tail())\n",
    "\n",
    "if df.empty==True or len(df)<input_sequence_length:\n",
    "    print(f\"There is enough data to make prediction during {dayAgo.strftime('%Y-%m-%d')} - {today}\")\n",
    "    # return \"no enough data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "327a7a76-24a7-4f8f-82c7-836c6a3778dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.dates as mdates\n",
    "# import seaborn as sns\n",
    "\n",
    "# plt.subplots(2, 1, figsize = (20, 10),sharex=True)\n",
    "\n",
    "# ax1 = plt.subplot(2, 1, 1)\n",
    "# plt.plot(df[['Close','EMA1','EMA2']])\n",
    "# plt.ylabel('Price & EMA')\n",
    "\n",
    "# ax2 = plt.subplot(2, 1, 2)\n",
    "# plt.plot(df[['MACD','SIGNAL']])\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('MACD & Signal')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546448a-234c-49d2-9a97-346a7e62ee25",
   "metadata": {},
   "source": [
    "# Get only Feature( 1 Indicator) to Predict itself in the next N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "36d29f68-fa93-42fc-903a-20ac2cc556ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Feature to Predict : EMA1 \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 30 entries, 2023-04-21 to 2023-06-02\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   EMA1    30 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 480.0 bytes\n",
      "None\n",
      "(30, 1)\n",
      "                EMA1\n",
      "Date                \n",
      "2023-04-21  317.1165\n",
      "2023-04-24  316.9044\n",
      "2023-04-25  315.6473\n",
      "2023-04-26  314.9605\n",
      "2023-04-27  315.9404\n",
      "                EMA1\n",
      "Date                \n",
      "2023-05-26  335.6150\n",
      "2023-05-30  338.2268\n",
      "2023-05-31  340.0019\n",
      "2023-06-01  342.1852\n",
      "2023-06-02  344.4516\n"
     ]
    }
   ],
   "source": [
    "print(f\"Get Feature to Predict : {prediction_col} \")\n",
    "dfForPred=df[feature_cols]\n",
    "#dfForPred=dfForPred.iloc[-(input_sequence_length+1):-1,:]\n",
    "dfForPred=dfForPred.iloc[-input_sequence_length:,:]\n",
    "print(dfForPred.info())\n",
    "print(dfForPred.shape)\n",
    "\n",
    "print(dfForPred.head(5))\n",
    "print(dfForPred.tail(5))\n",
    "\n",
    "# dfForPred.plot(figsize = (20, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306df85-1fb9-4e9e-9987-e42d6e2c84f5",
   "metadata": {},
   "source": [
    "# Make Pediction as Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0866a254-f643-4772-a239-9ff5621f89d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n",
      "[[0.7917154 ]\n",
      " [0.80044381]\n",
      " [0.80637603]\n",
      " [0.81367243]\n",
      " [0.82124653]]\n",
      "(1, 30, 1)\n",
      "1/1 [==============================] - 1s 644ms/step\n",
      "(1, 5) [[0.83877915 0.83968985 0.84124583 0.84317994 0.84354377]]\n",
      "(5, 1) [[349.6979 ]\n",
      " [349.9704 ]\n",
      " [350.436  ]\n",
      " [351.01474]\n",
      " [351.1236 ]]\n",
      "============================Summary============================\n",
      "(30, 1)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "xUnscaled=dfForPred.values #print(xUnscaled.shape)\n",
    "xScaled=x_scaler.transform(xUnscaled)\n",
    "print(xScaled.shape)\n",
    "print(xScaled[-5:])\n",
    "\n",
    "# # Way1\n",
    "# xScaledToPredict = []\n",
    "# xScaledToPredict.append(xScaled)\n",
    "# print(len(xScaledToPredict))\n",
    "\n",
    "# yPredScaled=x_model.predict(np.array(xScaledToPredict))\n",
    "# print(yPredScaled.shape,yPredScaled)\n",
    "\n",
    "# yPred  = x_scalerPred.inverse_transform(yPredScaled.reshape(-1, 1))\n",
    "# print(yPred.shape,yPred)\n",
    "\n",
    "#Way2\n",
    "xScaledToPredict= xScaled.reshape(1,input_sequence_length,len(feature_cols))\n",
    "print(xScaledToPredict.shape)\n",
    "\n",
    "yPredScaled = x_model.predict(xScaledToPredict)\n",
    "print(yPredScaled.shape, yPredScaled)\n",
    "\n",
    "yPred = x_scalerPred.inverse_transform(yPredScaled).reshape(-1, 1)\n",
    "print(yPred.shape, yPred)\n",
    "\n",
    "\n",
    "print(\"============================Summary============================\")\n",
    "print(xUnscaled.shape)\n",
    "print(yPred.shape)\n",
    "\n",
    "# print(\"============================Input============================\")\n",
    "# print(xUnscaled)\n",
    "# print(\"============================Output============================\")\n",
    "# print(yPred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a97710-b915-4d94-baec-9ffedca2ef73",
   "metadata": {},
   "source": [
    "# Build Predition Result Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893eae3-3adf-4eb6-815a-df7905520da6",
   "metadata": {},
   "source": [
    "## Feature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9fb7d106-f6c2-47dd-99db-f764b8697e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n",
      "                EMA1\n",
      "Date                \n",
      "2023-04-21  317.1165\n",
      "2023-04-24  316.9044\n",
      "2023-04-25  315.6473\n",
      "2023-04-26  314.9605\n",
      "2023-04-27  315.9404\n",
      "                EMA1\n",
      "Date                \n",
      "2023-05-26  335.6150\n",
      "2023-05-30  338.2268\n",
      "2023-05-31  340.0019\n",
      "2023-06-01  342.1852\n",
      "2023-06-02  344.4516\n"
     ]
    }
   ],
   "source": [
    "dfFeature=pd.DataFrame(data= xUnscaled,columns=feature_cols,index=dfForPred.index)\n",
    "\n",
    "print(dfFeature.shape)\n",
    "print(dfFeature.head())\n",
    "print(dfFeature.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b51723-9516-4297-b40e-61cd1d6375e1",
   "metadata": {},
   "source": [
    "## Forecast Value Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e9c1f307-5e3e-4ea5-9e3f-fe614518819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2023-06-05', '2023-06-06', '2023-06-07', '2023-06-08',\n",
      "               '2023-06-09'],\n",
      "              dtype='datetime64[ns]', freq='B')\n",
      "(5, 1)\n",
      "                  EMA1\n",
      "Date                  \n",
      "2023-06-05  349.697906\n",
      "2023-06-06  349.970398\n",
      "2023-06-07  350.436005\n",
      "2023-06-08  351.014740\n",
      "2023-06-09  351.123596\n"
     ]
    }
   ],
   "source": [
    "lastRowOfFeature=dfFeature.index.max()\n",
    "firstRowofPrediction=lastRowOfFeature+timedelta(days=1)\n",
    "datePred=pd.date_range(start=firstRowofPrediction,freq='b',periods=output_sequence_length)\n",
    "print(datePred)\n",
    "\n",
    "dfPrediction=pd.DataFrame(data= yPred,columns=feature_cols,index=datePred)\n",
    "dfPrediction.index.name=date_col\n",
    "print(dfPrediction.shape)\n",
    "print(dfPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0e321c-4fa0-4d78-8678-99b9b925a2ec",
   "metadata": {},
   "source": [
    "# Get Prepraed To ingest data into BQ , we have to create dataframe and convert to Json-Rowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bbf27cb7-663b-4b63-866e-547b3a4e45e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   prediction_date  1 non-null      object\n",
      " 1   asset_name       1 non-null      object\n",
      " 2   prediction_name  1 non-null      object\n",
      " 3   pred_timestamp   1 non-null      object\n",
      "dtypes: object(4)\n",
      "memory usage: 160.0+ bytes\n",
      "None\n",
      "  prediction_date asset_name prediction_name       pred_timestamp\n",
      "0      2023-06-02        QQQ            EMA1  2023-06-10 04:14:08\n"
     ]
    }
   ],
   "source": [
    "outputDF=pd.DataFrame(data=[ [today,asset_name,prediction_col,dtStr_imported] ],columns=[\"prediction_date\",\"asset_name\",\"prediction_name\",\"pred_timestamp\"])\n",
    "print(outputDF.info())\n",
    "print(outputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c89e2d97-1f3d-41bf-9b50-e22e94ef8457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prediction_date': '2023-06-02',\n",
       "  'asset_name': 'QQQ',\n",
       "  'prediction_name': 'EMA1',\n",
       "  'pred_timestamp': '2023-06-10 04:14:08',\n",
       "  'feature_for_prediction': [{'input_date': '2023-04-21',\n",
       "    'input_feature': 317.1165},\n",
       "   {'input_date': '2023-04-24', 'input_feature': 316.9044},\n",
       "   {'input_date': '2023-04-25', 'input_feature': 315.6473},\n",
       "   {'input_date': '2023-04-26', 'input_feature': 314.9605},\n",
       "   {'input_date': '2023-04-27', 'input_feature': 315.9404},\n",
       "   {'input_date': '2023-04-28', 'input_feature': 317.144},\n",
       "   {'input_date': '2023-05-01', 'input_feature': 318.0614},\n",
       "   {'input_date': '2023-05-02', 'input_feature': 318.3012},\n",
       "   {'input_date': '2023-05-03', 'input_feature': 318.1173},\n",
       "   {'input_date': '2023-05-04', 'input_feature': 317.7633},\n",
       "   {'input_date': '2023-05-05', 'input_feature': 318.6954},\n",
       "   {'input_date': '2023-05-08', 'input_feature': 319.6035},\n",
       "   {'input_date': '2023-05-09', 'input_feature': 319.9738},\n",
       "   {'input_date': '2023-05-10', 'input_feature': 320.9131},\n",
       "   {'input_date': '2023-05-11', 'input_feature': 321.8743},\n",
       "   {'input_date': '2023-05-12', 'input_feature': 322.4481},\n",
       "   {'input_date': '2023-05-15', 'input_feature': 323.2375},\n",
       "   {'input_date': '2023-05-16', 'input_feature': 323.9507},\n",
       "   {'input_date': '2023-05-17', 'input_feature': 325.2542},\n",
       "   {'input_date': '2023-05-18', 'input_feature': 327.4389},\n",
       "   {'input_date': '2023-05-19', 'input_feature': 329.0882},\n",
       "   {'input_date': '2023-05-22', 'input_feature': 330.6431},\n",
       "   {'input_date': '2023-05-23', 'input_feature': 331.1371},\n",
       "   {'input_date': '2023-05-24', 'input_feature': 331.2303},\n",
       "   {'input_date': '2023-05-25', 'input_feature': 332.7739},\n",
       "   {'input_date': '2023-05-26', 'input_feature': 335.615},\n",
       "   {'input_date': '2023-05-30', 'input_feature': 338.2268},\n",
       "   {'input_date': '2023-05-31', 'input_feature': 340.0019},\n",
       "   {'input_date': '2023-06-01', 'input_feature': 342.1852},\n",
       "   {'input_date': '2023-06-02', 'input_feature': 344.4516}],\n",
       "  'prediction_result': [{'output_date': '2023-06-05',\n",
       "    'output_value': 349.6979064941},\n",
       "   {'output_date': '2023-06-06', 'output_value': 349.9703979492},\n",
       "   {'output_date': '2023-06-07', 'output_value': 350.4360046387},\n",
       "   {'output_date': '2023-06-08', 'output_value': 351.0147399902},\n",
       "   {'output_date': '2023-06-09', 'output_value': 351.1235961914}]}]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonOutput = json.loads(outputDF.to_json(orient = 'records'))\n",
    "for item in jsonOutput:\n",
    "    \n",
    "    dataFeature=dfFeature.reset_index()[[date_col,prediction_col]]\n",
    "    dataFeature[date_col]=dataFeature[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataFeature.columns=[\"input_date\",\"input_feature\"]\n",
    "    jsonFeature= json.loads(dataFeature.to_json(orient = 'records'))\n",
    "    item[\"feature_for_prediction\"]=jsonFeature\n",
    "    \n",
    "    dataPred=dfPrediction.reset_index()[[date_col,prediction_col]]\n",
    "    dataPred[date_col]=dataPred[date_col].dt.strftime('%Y-%m-%d')\n",
    "    dataPred.columns=[\"output_date\",\"output_value\"]\n",
    "    jsonPred= json.loads(dataPred.to_json(orient = 'records'))\n",
    "    item[\"prediction_result\"]=jsonPred\n",
    " \n",
    "with open(\"fin_prediction.json\", \"w\") as outfile:\n",
    "    json.dump(jsonOutput, outfile)\n",
    "jsonOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061e560-fba8-478e-8eb3-70e2922ec302",
   "metadata": {},
   "source": [
    "# Ingest Data to BigQuery "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bf9c75db-619f-4cf1-be6f-c63d498cc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table pongthorn.FinAssetForecast.fin_movement_forecast already exists.\n",
      "[SchemaField('prediction_result', 'RECORD', 'REPEATED', None, None, (SchemaField('output_value', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('output_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('prediction_date', 'DATE', 'NULLABLE', None, None, (), None), SchemaField('feature_for_prediction', 'RECORD', 'REPEATED', None, None, (SchemaField('input_feature', 'FLOAT', 'NULLABLE', None, None, (), None), SchemaField('input_date', 'DATE', 'NULLABLE', None, None, (), None)), None), SchemaField('pred_timestamp', 'TIMESTAMP', 'NULLABLE', None, None, (), None), SchemaField('prediction_name', 'STRING', 'NULLABLE', None, None, (), None), SchemaField('asset_name', 'STRING', 'NULLABLE', None, None, (), None)]\n",
      "import to bigquery successfully  1 records\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    table=client.get_table(table_id)\n",
    "    print(\"Table {} already exists.\".format(table_id))\n",
    "    print(table.schema)\n",
    "except Exception as ex :\n",
    "    print(str(ex))\n",
    "#if error  please create table and other configuration as  bq_prediction.txt    \n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "# schema=[  ]\n",
    ")\n",
    "\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND  \n",
    "#job_config.write_disposition = bigquery.WriteDisposition.WRITE_TRUNCATE\n",
    "job = client.load_table_from_json(jsonOutput,table_id, job_config = job_config)\n",
    "if job.errors is not None:\n",
    "    print(job.error_result)\n",
    "    print(job.errors)\n",
    "else:\n",
    "    print(f\"import to bigquery successfully  {len(jsonOutput)} records\")\n",
    "    \n",
    "#job_config.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8e3a9e58-62e1-46cf-a25e-1774d45dfee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return   'completed job.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef245de-ad6a-4315-8505-2c1fdba16af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467828a9-b291-4816-b1a2-26e63855b046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116348e-3b7a-4216-9283-191c97652b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
